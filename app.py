import json
import streamlit as st
import pandas as pd
from sqlalchemy import text
from pathlib import Path

# å¤ç”¨ä½ é¡¹ç›®ç°æœ‰çš„é…ç½®
from settings import get_engine

# ===========================
# 0. æ ¸å¿ƒé…ç½® (Config)
# ===========================

# å®šä¹‰å—è¯•è€… ID çš„â€œåˆ«ååˆ—è¡¨â€ (æŒ‰ä¼˜å…ˆçº§æŸ¥æ‰¾)
# ç³»ç»Ÿä¼šä¾æ¬¡æ£€æŸ¥è¡¨ä¸­æ˜¯å¦å­˜åœ¨è¿™äº›åˆ—ï¼Œæ‰¾åˆ°ç¬¬ä¸€ä¸ªå­˜åœ¨çš„å°±ç”¨å®ƒä½œä¸º Join Key
SUBJECT_ID_ALIASES = [
    "SUBJECTID",   # æ ‡å‡†åç§° (æœ€ä¼˜å…ˆ)
    "SUBJID",      # å¸¸è§å˜ä½“
    "patient_id",  # å¤–éƒ¨æ•°æ®å¸¸è§åç§°
    "USUBJID"      # CDISC æ ‡å‡†åç§° (å¤‡ç”¨)
]

# ===========================
# 1. è¾…åŠ©å‡½æ•°
# ===========================

def load_table_metadata():
    """åŠ è½½è¡¨ç»“æ„ä¿¡æ¯"""
    # ä½¿ç”¨ç›¸å¯¹äºå½“å‰ app.py çš„è·¯å¾„ï¼Œé¿å…æ‰¾ä¸åˆ°æ–‡ä»¶
    base_dir = Path(__file__).resolve().parent
    json_path = base_dir / "db" / "table_columns.json"

    if json_path.exists():
        with open(json_path, "r", encoding="utf-8") as f:
            return json.load(f)
    else:
        st.error(f"æœªæ‰¾åˆ°è¡¨ç»“æ„æ–‡ä»¶: {json_path}ã€‚è¯·å…ˆè¿è¡Œ `python -m cough.db.exp_table_columns`ã€‚")
        return {}

def get_id_column(table_name, meta_data):
    """
    æ™ºèƒ½æŸ¥æ‰¾ï¼šæ ¹æ®é…ç½®çš„åˆ«ååˆ—è¡¨ï¼Œæ‰¾åˆ°è¯¥è¡¨å®é™…ä½¿ç”¨çš„ ID åˆ—åã€‚
    å¦‚æœæ²¡æ‰¾åˆ°ï¼Œè¿”å› Noneã€‚
    """
    available_columns = meta_data.get(table_name, [])
    
    for alias in SUBJECT_ID_ALIASES:
        if alias in available_columns:
            return alias
            
    return None

def build_sql(selected_tables, table_columns_map, filters, subject_blocklist, meta_data):
    """
    æ ¸å¿ƒï¼šæ ¹æ®ç”¨æˆ·çš„é€‰æ‹©ï¼ŒåŠ¨æ€æ‹¼æ¥ SQL è¯­å¥ (æ”¯æŒæ™ºèƒ½ ID æ˜ å°„)
    """
    if not selected_tables:
        return None

    # --- 1. ç¡®å®šä¸»è¡¨çš„ ID åˆ— ---
    base_table = selected_tables[0]
    base_id_col = get_id_column(base_table, meta_data)
    
    if not base_id_col:
        st.error(f"âŒ ä¸»è¡¨ `{base_table}` ä¸­æ‰¾ä¸åˆ°ä»»ä½•å·²çŸ¥çš„ ID åˆ— ({SUBJECT_ID_ALIASES})ï¼Œæ— æ³•ä½œä¸ºä¸»è¡¨ã€‚")
        return None

    # --- 2. æ„å»º SELECT éƒ¨åˆ† ---
    select_clauses = []
    
    # å¼ºåˆ¶æŠŠä¸»è¡¨çš„ ID é€‰å‡ºæ¥ï¼Œå¹¶ç»Ÿä¸€é‡å‘½åä¸º 'SUBJECTID' æ–¹ä¾¿æŸ¥çœ‹
    select_clauses.append(f"`{base_table}`.`{base_id_col}` AS `SUBJECTID`") 

    for table in selected_tables:
        cols = table_columns_map.get(table, [])
        for col in cols:
            # å¦‚æœè¿™ä¸€åˆ—å°±æ˜¯è¯¥è¡¨çš„ ID åˆ—ï¼Œæˆ‘ä»¬è·³è¿‡ï¼ˆå› ä¸ºå·²ç»å¼ºåˆ¶åŠ åœ¨ç¬¬ä¸€åˆ—äº†ï¼‰ï¼Œæˆ–è€…ä½ å¯ä»¥ä¿ç•™ä½†æ”¹å
            # è¿™é‡Œç®€å•èµ·è§ï¼šä¿ç•™ï¼Œå‘½åä¸º Table_Col
            select_clauses.append(f"`{table}`.`{col}` AS `{table}_{col}`")

    select_sql = "SELECT\n    " + ",\n    ".join(select_clauses)

    # --- 3. æ„å»º FROM å’Œ LEFT JOIN éƒ¨åˆ† ---
    from_sql = f"\nFROM `{base_table}`"
    
    join_sql = ""
    # ä»ç¬¬äºŒä¸ªè¡¨å¼€å§‹éå†
    for i in range(1, len(selected_tables)):
        current_table = selected_tables[i]
        
        # æ‰¾åˆ°å½“å‰è¿™ä¸ªè¡¨çš„ ID åˆ—å
        current_id_col = get_id_column(current_table, meta_data)
        
        if not current_id_col:
            st.warning(f"âš ï¸ è¡¨ `{current_table}` ä¸­æ‰¾ä¸åˆ° ID åˆ—ï¼Œå°†æ— æ³•æ­£ç¡® Join (SQL ä¸­ä¼šç•™ç©ºï¼Œè¯·æ‰‹åŠ¨æ£€æŸ¥)ã€‚")
            # é™çº§å¤„ç†ï¼šè¿˜æ˜¯é»˜è®¤ SUBJECTIDï¼Œé˜²æ­¢ SQL å½»åº•æŠ¥é”™æ— æ³•ç”Ÿæˆ
            current_id_col = "SUBJECTID" 

        # é€»è¾‘ï¼šLEFT JOIN TableB ON BaseTable.BaseID = TableB.CurrentID
        join_sql += f"\nLEFT JOIN `{current_table}` ON `{base_table}`.`{base_id_col}` = `{current_table}`.`{current_id_col}`"

    # --- 4. æ„å»º WHERE éƒ¨åˆ† ---
    where_conditions = []
    
    # 4.1 å¤„ç†é»‘åå• (ä½¿ç”¨ä¸»è¡¨çš„ ID åˆ—)
    if subject_blocklist:
        ids = [x.strip() for x in subject_blocklist.replace("ï¼Œ", ",").split("\n") if x.strip()]
        if ids:
            id_list_str = "', '".join(ids)
            where_conditions.append(f"`{base_table}`.`{base_id_col}` NOT IN ('{id_list_str}')")

    # 4.2 è‡ªå®šä¹‰ WHERE
    if filters.get("custom_where"):
        where_conditions.append(filters["custom_where"])

    where_sql = ""
    if where_conditions:
        where_sql = "\nWHERE " + "\n  AND ".join(where_conditions)

    # --- 5. æ„å»º GROUP BY / HAVING ---
    group_by_sql = ""
    if filters.get("group_by"):
        # è¿˜åŸåˆ—å (Table_Column -> Table.Column)
        # è¿™é‡Œçš„å¤„ç†æ¯”è¾ƒç®€å•ï¼Œå‡è®¾ç”¨æˆ·é€‰çš„éƒ½æ˜¯æ ‡å‡†ç”Ÿæˆçš„ Table_Col
        group_cols_sql = []
        for c in filters["group_by"]:
            # c çš„æ ¼å¼æ˜¯ "TableName_ColName"
            # æˆ‘ä»¬éœ€è¦åå‘æ‰¾åˆ°å®ƒå±äºå“ªä¸ªè¡¨ã€‚æœ€ç®€å•çš„æ–¹æ³•æ˜¯æ‹†åˆ†å­—ç¬¦ä¸²ï¼Œä½†è¿™æœ‰é£é™©ï¼ˆå¦‚æœè¡¨åå¸¦ä¸‹åˆ’çº¿ï¼‰ã€‚
            # æ›´ç¨³å¦¥çš„æ–¹æ³•æ˜¯å» table_columns_map é‡ŒæŸ¥ã€‚
            found = False
            for tbl, t_cols in table_columns_map.items():
                for t_col in t_cols:
                    if f"{tbl}_{t_col}" == c:
                        group_cols_sql.append(f"`{tbl}`.`{t_col}`")
                        found = True
                        break
                if found: break
        
        if group_cols_sql:
            group_by_sql = "\nGROUP BY " + ", ".join(group_cols_sql)

    having_sql = ""
    if filters.get("having"):
        having_sql = "\nHAVING " + filters["having"]

    # --- 6. ç»„è£… ---
    final_sql = f"{select_sql}{from_sql}{join_sql}{where_sql}{group_by_sql}{having_sql};"
    return final_sql

# ===========================
# 2. ç•Œé¢å¸ƒå±€ (Streamlit)
# ===========================

st.set_page_config(page_title="ä¸´åºŠæ•°æ®æ‹¼è¡¨å™¨", layout="wide")
st.title("ğŸ¥ ä¸´åºŠè¯•éªŒæ•°æ®æ‹¼è¡¨å·¥å…·")

# åŠ è½½å…ƒæ•°æ®
meta_data = load_table_metadata()
all_tables = list(meta_data.keys())

# --- ä¾§è¾¹æ  ---
with st.sidebar:
    st.header("âš™ï¸ å…¨å±€é…ç½®")
    
    # æ˜¾ç¤ºå½“å‰çš„ ID æ˜ å°„è§„åˆ™
    st.info(f"ğŸ”— æ™ºèƒ½ Join é€»è¾‘å·²å¯ç”¨ã€‚\n\nç³»ç»Ÿå°†æŒ‰ä»¥ä¸‹ä¼˜å…ˆé¡ºåºæŸ¥æ‰¾å„è¡¨çš„å…³è”é”®ï¼š\n\n" + " -> ".join(SUBJECT_ID_ALIASES))
    
    st.subheader("ğŸš« å—è¯•è€…é»‘åå• (Not In)")
    subject_blocklist = st.text_area(
        "è¾“å…¥è¦æ’é™¤çš„ ID (ä¸€è¡Œä¸€ä¸ª):",
        height=150,
        placeholder="1001\n1002"
    )

# --- ä¸»ç•Œé¢ ---

st.subheader("1. é€‰æ‹©è¦æ‹¼æ¥çš„è¡¨ (æŒ‰ Join é¡ºåº)")
selected_tables = st.multiselect(
    "è¯·é€‰æ‹©è¡¨ (ç¬¬ä¸€ä¸ªé€‰ä¸­çš„å°†ä½œä¸ºä¸»è¡¨):",
    options=all_tables,
    default=None
)

if not selected_tables:
    st.warning("è¯·è‡³å°‘é€‰æ‹©ä¸€å¼ è¡¨ã€‚")
    st.stop()

# å®æ—¶æ£€æŸ¥ä¸»è¡¨çš„ ID
main_tbl = selected_tables[0]
main_id = get_id_column(main_tbl, meta_data)
if main_id:
    st.success(f"âœ… ä¸»è¡¨ `{main_tbl}` å°†ä½¿ç”¨ `{main_id}` ä½œä¸ºå…³è”ä¸»é”®ã€‚")
else:
    st.error(f"âŒ è­¦å‘Šï¼šåœ¨ä¸»è¡¨ `{main_tbl}` ä¸­æœªæ‰¾åˆ°é…ç½®çš„ ID åˆ—ï¼Œè¯·æ£€æŸ¥è¡¨ç»“æ„æˆ–ä¿®æ”¹é…ç½®ã€‚")

st.subheader("2. é€‰æ‹©æ¯å¼ è¡¨è¦å±•ç¤ºçš„åˆ—")
table_columns_map = {} 
cols = st.columns(len(selected_tables))
all_selected_columns_ref = [] 

for idx, table_name in enumerate(selected_tables):
    available_cols = meta_data.get(table_name, [])
    
    # æ ‡æ³¨ä¸€ä¸‹è¯¥è¡¨ç”¨çš„æ˜¯å“ªä¸ª ID
    this_id = get_id_column(table_name, meta_data)
    id_label = f" (Key: {this_id})" if this_id else " (Key: â“)"
    
    with st.expander(f"è¡¨: {table_name}{id_label}", expanded=True):
        default_cols = available_cols[:5] if len(available_cols) > 0 else []
        selected_cols = st.multiselect(
            f"é€‰æ‹©å­—æ®µ:",
            options=available_cols,
            default=default_cols,
            key=f"select_{table_name}"
        )
        table_columns_map[table_name] = selected_cols
        for c in selected_cols:
            all_selected_columns_ref.append(f"{table_name}_{c}")

# --- é«˜çº§ç­›é€‰ ---
st.subheader("3. é«˜çº§ç­›é€‰ (SQL)")
col1, col2, col3 = st.columns(3)
filters = {}
with col1:
    filters["custom_where"] = st.text_input("WHERE æ¡ä»¶", placeholder="ä¾‹å¦‚: `adsl`.`AGE` > 18")
with col2:
    filters["group_by"] = st.multiselect("GROUP BY å­—æ®µ", options=all_selected_columns_ref)
with col3:
    filters["having"] = st.text_input("HAVING æ¡ä»¶", placeholder="ä¾‹å¦‚: count(*) > 1")

# --- ç”Ÿæˆ ---
st.divider()

if st.button("ğŸš€ ç”Ÿæˆå¤§è¡¨å¹¶é¢„è§ˆ", type="primary"):
    # ä¼ å…¥ meta_data ä»¥ä¾›æŸ¥è¯¢åˆ—å
    sql = build_sql(selected_tables, table_columns_map, filters, subject_blocklist, meta_data)
    
    if sql:
        st.subheader("ç”Ÿæˆçš„ SQL è¯­å¥:")
        st.code(sql, language="sql")
        
        try:
            engine = get_engine()
            with st.spinner("æ­£åœ¨ä»æ•°æ®åº“æŸ¥è¯¢æ•°æ®..."):
                df_result = pd.read_sql(sql, engine)
                
            st.success(f"æŸ¥è¯¢æˆåŠŸï¼å…±æ‰¾åˆ° {len(df_result)} è¡Œæ•°æ®ã€‚")
            st.dataframe(df_result, use_container_width=True)
            
            csv = df_result.to_csv(index=False).encode('utf-8-sig')
            st.download_button(
                label="ğŸ“¥ ä¸‹è½½ç»“æœä¸º CSV",
                data=csv,
                file_name="cohort_data.csv",
                mime="text/csv",
            )
            
        except Exception as e:
            st.error(f"æŸ¥è¯¢å‡ºé”™: {e}")
    else:
        st.error("ç”Ÿæˆå¤±è´¥ï¼Œè¯·æ£€æŸ¥é…ç½®ã€‚")