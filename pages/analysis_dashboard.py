import html
import json
from urllib.parse import urlencode
from typing import Any, Dict, List

import pandas as pd
import copy
import streamlit as st
from streamlit import config as st_config
from scipy import stats  # ç”¨äºè®¡ç®— ANOVA

from settings import get_engine
from utils import (
    fetch_all_setups,
    fetch_setup_config,
    load_table_metadata,
    build_sql,
    save_calculation_config
)

# å¼•å…¥æ’ä»¶ç³»ç»Ÿ
from analysis_methods import CALC_METHODS, AGG_METHODS
# å¼•å…¥ç‹¬ç«‹çš„å›¾è¡¨ç»„ä»¶
from charts.classic import draw_spaghetti_chart, build_spaghetti_fig, render_spaghetti_fig
from charts.uniform import (
    build_uniform_spaghetti_fig,
    compute_uniform_axes,
    render_uniform_spaghetti_fig,
)
from exports.charts import build_charts_export_html
from exports.common import df_to_csv_bytes
from exports.pivot import nested_pivot_to_excel_bytes
from views.pivot_classic import render_pivot_classic
from views.pivot_nested import render_pivot_nested

st.set_page_config(page_title="åˆ†æä»ªè¡¨ç›˜", layout="wide")
st.title("ğŸ“Š åˆ†æä»ªè¡¨ç›˜")
st.markdown(
    """
    <style>
    section.main > div.block-container {
        max-width: 100%;
        padding-left: 2rem;
        padding-right: 2rem;
    }
    </style>
    """,
    unsafe_allow_html=True,
)


# ==========================================
# æ ¸å¿ƒé€»è¾‘å±‚ (Core Logic)
# ==========================================

def run_analysis(config: Dict[str, Any]) -> tuple[str, pd.DataFrame]:
    """ETLå±‚ï¼šç”ŸæˆSQLå¹¶è·å–åŸå§‹æ•°æ®"""
    meta_data = load_table_metadata()
    
    selected_tables = config.get("selected_tables", [])
    table_columns_map = config.get("table_columns_map", {})
    filters = config.get("filters", {})
    subject_blocklist = config.get("subject_blocklist", "")

    sql = build_sql(
        selected_tables=selected_tables,
        table_columns_map=table_columns_map,
        filters=filters,
        subject_blocklist=subject_blocklist,
        meta_data=meta_data,
    )

    if not sql:
        st.error("é…ç½®é”™è¯¯ï¼šæ— æ³•ç”Ÿæˆæœ‰æ•ˆ SQLã€‚è¯·æ£€æŸ¥é€‰è¡¨æˆ–ç­›é€‰æ¡ä»¶ã€‚")
        return "", pd.DataFrame()

    engine = get_engine()
    with st.spinner("æ­£åœ¨æŸ¥è¯¢æ•°æ®åº“..."):
        # è®¾ç½®è¶…æ—¶é˜²æ­¢å¡æ­»
        with engine.connect().execution_options(timeout=60) as conn:
            df = pd.read_sql(sql, conn)
            
    return sql, df


def apply_baseline_mapping(df: pd.DataFrame, config: Dict) -> pd.DataFrame:
    """
    [BDS å¼•æ“] åŸºçº¿å˜é‡æ˜ å°„
    å°†çºµå‘æ•°æ® (Long Format) ä¸­çš„åŸºçº¿è¡Œæ•°å€¼ï¼Œæ¨ªå‘å¹¿æ’­åˆ°è¯¥å—è¯•è€…çš„æ¯ä¸€è¡Œã€‚
    """
    if not config or not isinstance(config, dict):
        return df
    
    subj_col = config.get("subj_col")
    visit_col = config.get("visit_col")
    baseline_val = config.get("baseline_val")
    target_cols = config.get("target_cols", [])

    if not (subj_col and visit_col and baseline_val and target_cols):
        return df
    
    # å®¹é”™ï¼šç¡®ä¿æ‰€éœ€åˆ—å­˜åœ¨
    available_targets = [c for c in target_cols if c in df.columns]
    if not available_targets:
        return df
    if subj_col not in df.columns or visit_col not in df.columns:
        return df

    # 1. æå–åŸºçº¿å­é›†
    # ç­›é€‰å‡º Visit == Baseline çš„è¡Œ
    bl_mask = df[visit_col].astype(str) == str(baseline_val)
    bl_df = df.loc[bl_mask, [subj_col] + available_targets].copy()
    
    # 2. é‡å‘½åç”Ÿæˆ _BL åç¼€
    rename_map = {col: f"{col}_BL" for col in available_targets}
    bl_df = bl_df.rename(columns=rename_map)
    
    # 3. å»é‡ (ç¡®ä¿æ¯ä¸ªå—è¯•è€…åªæœ‰ä¸€è¡ŒåŸºçº¿)
    bl_df = bl_df.drop_duplicates(subset=[subj_col])

    # 4. åˆå¹¶å›ä¸»è¡¨ (Left Join)
    merged_df = pd.merge(df, bl_df, on=subj_col, how="left")
    
    return merged_df


def apply_calculations(df: pd.DataFrame, rules: List[Dict]) -> pd.DataFrame:
    """
    [è®¡ç®—å¼•æ“] æ‰§è¡Œè®¡ç®—è§„åˆ™
    æ”¯æŒé™é»˜å¤±è´¥ï¼Œä»¥ä¾¿æ”¯æŒä¸¤æ®µå¼è®¡ç®— (Two-Pass Calculation)ã€‚
    """
    df_calc = df.copy()
    
    for rule in rules:
        try:
            name = rule['name']
            cols = rule['cols']
            method_name = rule['method']
            
            # éªŒè¯åˆ—æ˜¯å¦å­˜åœ¨
            valid_cols = [c for c in cols if c in df_calc.columns]
            
            # å¦‚æœæ‰€éœ€åˆ—ä¸å…¨ï¼ˆæ¯”å¦‚ç¼ºäº†åŸºçº¿åˆ—ï¼‰ï¼Œåœ¨ Pass 1 é˜¶æ®µè·³è¿‡
            if len(valid_cols) < len(cols):
                continue

            # å¼ºåˆ¶è½¬æ•°å€¼
            subset = df_calc[valid_cols].apply(pd.to_numeric, errors='coerce')

            # è°ƒç”¨æ’ä»¶
            if method_name in CALC_METHODS:
                calc_func = CALC_METHODS[method_name]
                df_calc[name] = calc_func(subset)
                
        except Exception:
            # é™é»˜å¤±è´¥ï¼Œå…è®¸ Pass 2 é‡è¯•
            pass
            
    return df_calc


def calculate_anova_table(df: pd.DataFrame, index_col: str, group_col: str, value_col: str) -> pd.DataFrame:
    """
    [ç»Ÿè®¡å¼•æ“] è®¡ç®—ç»„é—´å·®å¼‚ (One-Way ANOVA)
    è‡ªåŠ¨åŸºäºé€è§†è¡¨çš„ç»´åº¦è¿›è¡Œè®¡ç®—ã€‚
    """
    results = []
    
    # ç¡®ä¿æ•°å€¼æœ‰æ•ˆ
    clean_df = df.dropna(subset=[value_col, group_col])
    clean_df[value_col] = pd.to_numeric(clean_df[value_col], errors='coerce')
    
    # 1. éå†è¡Œç»´åº¦ (å¦‚: Day 14, Day 28)
    row_levels = clean_df[index_col].unique()
    
    for level in row_levels:
        # å–å‡ºè¿™ä¸€å±‚çš„æ•°æ®
        sub_df = clean_df[clean_df[index_col] == level]
        
        # 2. æŒ‰ç»„æå–æ•°æ®
        groups_data = []
        groups = sub_df[group_col].unique()
        
        if len(groups) < 2:
            results.append({
                "Layer": level, "F-value": None, "P-value": None, "Note": "ç»„æ•°ä¸è¶³(<2)"
            })
            continue
            
        # æå–æ¯ä¸€ç»„çš„æ•°å€¼åˆ—è¡¨
        for g in groups:
            vals = sub_df[sub_df[group_col] == g][value_col].dropna().values
            if len(vals) > 1: 
                groups_data.append(vals)
        
        # 3. è®¡ç®— F/P
        if len(groups_data) >= 2:
            try:
                f_stat, p_val = stats.f_oneway(*groups_data)
                results.append({
                    "Layer": level,
                    "F-value": f_stat,
                    "P-value": p_val,
                    "Note": "Significant" if p_val < 0.05 else ""
                })
            except Exception:
                results.append({"Layer": level, "F-value": None, "P-value": None, "Note": "Calc Error"})
        else:
            results.append({"Layer": level, "F-value": None, "P-value": None, "Note": "æ•°æ®ä¸è¶³"})
            
    res_df = pd.DataFrame(results)
    if not res_df.empty:
        # æ ¼å¼åŒ–æ˜¾ç¤º
        res_df["F-value"] = res_df["F-value"].apply(lambda x: f"{x:.3f}" if pd.notnull(x) else "-")
        res_df["P-value"] = res_df["P-value"].apply(lambda x: f"{x:.4f}" if pd.notnull(x) else "-")
        # æ’åº
        try:
            res_df = res_df.sort_values("Layer")
        except:
            pass
        
    return res_df


# ==========================================
# UI è¡¨ç°å±‚ (Main)
# ==========================================

def main() -> None:
    # --- 1. ä¾§è¾¹æ  ---
    with st.sidebar:
        st.header("ğŸ§© åˆ†æé›†é…ç½®")
        setups = fetch_all_setups()

        if not setups:
            st.info("æš‚æ— é…ç½®ã€‚è¯·å…ˆå»ä¸»é¡µåˆ›å»ºã€‚")
            return

        option_labels = [f"{row['setup_name']}" for row in setups]
        selected_label = st.selectbox("é€‰æ‹©é…ç½®", options=option_labels)
        selected_row = next(r for r in setups if f"{r['setup_name']}" == selected_label)
        
        if selected_row.get("description"):
            st.info(f"ğŸ“ **å¤‡æ³¨**: {selected_row['description']}")

    # --- 1.1 çŠ¶æ€ç®¡ç†ä¸åˆå§‹åŒ– ---
    if "current_setup_name" not in st.session_state:
        st.session_state["current_setup_name"] = selected_row["setup_name"]
        need_reload = True
    else:
        need_reload = st.session_state["current_setup_name"] != selected_row["setup_name"]

    if need_reload:
        st.session_state["current_setup_name"] = selected_row["setup_name"]
        
        cfg_pack = fetch_setup_config(selected_row["setup_name"]) or {}
        calc_cfg = cfg_pack.get("calculation") or {}
        if isinstance(calc_cfg, list): calc_cfg = {"calc_rules": calc_cfg}
        
        st.session_state["calc_rules"] = calc_cfg.get("calc_rules", [])
        st.session_state["calc_note"] = calc_cfg.get("note", "")
        st.session_state["exclusions"] = calc_cfg.get("exclusions", [])
        st.session_state["pivot_config"] = calc_cfg.get("pivot", {})
        st.session_state["baseline_config"] = calc_cfg.get("baseline", {}) 

        p_cfg = st.session_state["pivot_config"]
        # å…¼å®¹å†å²æ•°æ®ï¼šæ—©æœŸç‰ˆæœ¬å¯èƒ½ä½¿ç”¨ç®€å•å­—ç¬¦ä¸² 'mean' ä½œä¸ºèšåˆå‡½æ•°åï¼Œ
        # ç°åœ¨ç»Ÿä¸€ä¸ºèšåˆå‡½æ•°åç§°åˆ—è¡¨ã€‚
        raw_agg = p_cfg.get("agg", ["Mean - å¹³å‡å€¼"])
        if isinstance(raw_agg, str):
            if raw_agg == "mean":
                raw_agg = "Mean - å¹³å‡å€¼"
            raw_aggs = [raw_agg]
        else:
            raw_aggs = list(raw_agg)

        st.session_state["pivot_index"] = p_cfg.get("index", [])
        st.session_state["pivot_columns"] = p_cfg.get("columns", [])
        st.session_state["pivot_values"] = p_cfg.get("values", [])
        st.session_state["pivot_aggs"] = raw_aggs
        st.session_state["pivot_view_mode"] = p_cfg.get("view", "classic")
        row_order_cfg = p_cfg.get("row_order", {})
        if not isinstance(row_order_cfg, dict):
            row_order_cfg = {}
        st.session_state["pivot_row_order_field"] = row_order_cfg.get("field")
        st.session_state["pivot_row_order_values"] = list(
            row_order_cfg.get("values", [])
        )

        st.session_state.pop("raw_df", None)
        st.session_state.pop("current_sql", None)
        st.session_state.pop("selected_subject_id", None)

    # --- 2. åŠ è½½æºæ•°æ® ---
    if st.button("ğŸš€ åŠ è½½æºæ•°æ®", type="primary"):
        full_cfg = fetch_setup_config(selected_row["setup_name"])
        if full_cfg and full_cfg.get("extraction"):
            sql, df_res = run_analysis(full_cfg["extraction"])
            if not df_res.empty:
                st.session_state["raw_df"] = df_res
                st.session_state["current_sql"] = sql
                st.success(f"åŠ è½½æˆåŠŸï¼å…± {len(df_res)} è¡Œã€‚")
            else:
                st.warning("æŸ¥è¯¢ç»“æœä¸ºç©ºã€‚")

    # --- 3. æ•°æ®å¤„ç†æµæ°´çº¿ ---
    if "raw_df" in st.session_state:
        raw_df = st.session_state["raw_df"]
        
        # -------------------------------------------------------
        # ã€Step 2ã€‘åŸå§‹ SQL + åŸå§‹æ•°æ®æ¸…å•é¢„è§ˆ
        # -------------------------------------------------------
        with st.expander("æŸ¥çœ‹åŸå§‹ SQL"):
            st.code(st.session_state.get("current_sql", ""), language="sql")

        # åŸå§‹æ•°æ®é¢„è§ˆï¼šå±•ç¤ºå®Œæ•´æ•°æ®æ¸…å•ï¼ˆå‡ ç™¾è¡Œçº§åˆ«ï¼‰
        with st.expander("ğŸ“„ åŸå§‹æ•°æ®é¢„è§ˆï¼ˆæŸ¥è¯¢ç»“æœï¼‰", expanded=False):
            st.dataframe(raw_df, width="stretch")
            st.download_button(
                "ğŸ“¥ ä¸‹è½½åŸå§‹æ•°æ®",
                df_to_csv_bytes(raw_df, index=False),
                "raw_data.csv",
            )

        st.divider()

        # -------------------------------------------------------
        # ã€Pass 1: é¢„è®¡ç®—ã€‘
        # å…ˆç®—ä¸€éè¡ç”Ÿå˜é‡ (å¦‚ Total)ï¼Œä¸ºäº†è®©åŸºçº¿é…ç½®èƒ½é€‰åˆ°å®ƒä»¬
        # -------------------------------------------------------
        df_pass1 = apply_calculations(raw_df, st.session_state["calc_rules"])
        all_cols_pass1 = list(df_pass1.columns)

        # ==========================================
        # [Step A] åŸºçº¿å˜é‡æ˜ å°„ (BDS Engine)
        # ==========================================
        st.subheader("ğŸ§¬ åŸºçº¿å˜é‡æ˜ å°„ (BDS)")
        st.caption("åœ¨æ­¤å®šä¹‰åŸºçº¿ï¼Œç³»ç»Ÿä¼šè‡ªåŠ¨ç”Ÿæˆ `_BL` åç¼€å˜é‡ã€‚")
        
        bl_cfg = st.session_state.get("baseline_config", {})
        
        with st.expander("âš™ï¸ é…ç½®åŸºçº¿é€»è¾‘", expanded=not bool(bl_cfg)):
            c1, c2, c3 = st.columns(3)
            # æ™ºèƒ½çŒœæµ‹
            def_subj_idx = next((i for i, c in enumerate(all_cols_pass1) if "SUBJ" in c.upper()), 0)
            def_visit_idx = next((i for i, c in enumerate(all_cols_pass1) if "VISIT" in c.upper() or "AVISIT" in c.upper()), 0)

            with c1:
                subj_col = st.selectbox("å—è¯•è€… ID åˆ—", all_cols_pass1, index=def_subj_idx, key="bl_subj_ui")
            with c2:
                visit_col = st.selectbox("è®¿è§†/æ—¶é—´ç‚¹åˆ—", all_cols_pass1, index=def_visit_idx, key="bl_visit_ui")
            
            # åŠ¨æ€è·å–è®¿è§†åˆ—è¡¨
            if visit_col and visit_col in df_pass1.columns:
                unique_visits = sorted(df_pass1[visit_col].dropna().astype(str).unique().tolist())
            else:
                unique_visits = []
                
            with c3:
                try:
                    saved_bl_val = bl_cfg.get("baseline_val")
                    bl_idx = unique_visits.index(saved_bl_val) if saved_bl_val in unique_visits else 0
                except:
                    bl_idx = 0
                baseline_val = st.selectbox("å“ªä¸€ä¸ªè®¿è§†æ˜¯åŸºçº¿?", unique_visits, index=bl_idx, key="bl_val_ui")
            
            target_cols = st.multiselect(
                "é€‰æ‹©æ•°å€¼å˜é‡ (ç”Ÿæˆ _BL åˆ—)", 
                options=all_cols_pass1,
                default=[c for c in bl_cfg.get("target_cols", []) if c in all_cols_pass1],
                key="bl_targets_ui"
            )
            
            if st.button("âœ… åº”ç”¨åŸºçº¿é…ç½®"):
                st.session_state["baseline_config"] = {
                    "subj_col": subj_col, "visit_col": visit_col,
                    "baseline_val": baseline_val, "target_cols": target_cols
                }
                st.rerun()

        if st.session_state.get("baseline_config"):
            targets = st.session_state["baseline_config"].get("target_cols", [])
            if targets:
                st.info(f"å·²ç”Ÿæˆå˜é‡: {', '.join([t+'_BL' for t in targets])}")

        st.divider()

        # ==========================================
        # [Step B] è¡ç”Ÿå˜é‡è®¡ç®—
        # ==========================================
        st.subheader("ğŸ§® è¡ç”Ÿå˜é‡è®¡ç®—")
        
        # æ¨¡æ‹ŸåŸºçº¿æ˜ å°„ä»¥è·å–åˆ—å
        df_preview_bl = apply_baseline_mapping(df_pass1, st.session_state.get("baseline_config", {}))
        current_cols = list(df_preview_bl.columns) + [r['name'] for r in st.session_state["calc_rules"]]
        
        with st.expander("â• æ·»åŠ æ–°è®¡ç®—è§„åˆ™", expanded=True):
            c1, c2, c3, c4 = st.columns([2, 3, 2, 1])
            with c1: 
                new_name = st.text_input("æ–°å˜é‡å", placeholder="ä¾‹: Change_Score")
            with c2: 
                targets_sel = st.multiselect("å‚ä¸è®¡ç®—çš„åˆ—", options=current_cols)
            with c3: 
                method = st.selectbox("è®¡ç®—æ–¹å¼", options=list(CALC_METHODS.keys()))
            with c4:
                st.write(""); st.write("")
                if st.button("æ·»åŠ "):
                    if new_name and targets_sel:
                        st.session_state["calc_rules"].append({
                            "name": new_name, "cols": targets_sel, "method": method
                        })
                        st.rerun()

        if st.session_state["calc_rules"]:
            for i, rule in enumerate(st.session_state["calc_rules"]):
                c1, c2 = st.columns([8, 1])
                c1.markdown(f"**Step {i+1}:** `{rule['name']}` = **{rule['method']}** ({', '.join(rule['cols'])})")
                if c2.button("ğŸ—‘ï¸", key=f"del_rule_{i}"):
                    st.session_state["calc_rules"].pop(i)
                    st.rerun()

        # ==========================================
        # [Step C] æ•°æ®å‰”é™¤
        # ==========================================
        st.divider()
        st.markdown("##### ğŸ—‘ï¸ æ•°æ®å‰”é™¤è§„åˆ™")
        
        with st.expander("é…ç½®å‰”é™¤æ¡ä»¶"):
            ec1, ec2 = st.columns([2, 3])
            cur_excl = st.session_state.get("exclusions", [])
            def_field = cur_excl[0]["field"] if cur_excl else (current_cols[0] if current_cols else None)
            def_vals = cur_excl[0]["values"] if cur_excl else []
            
            with ec1:
                try: f_idx = current_cols.index(def_field) if def_field in current_cols else 0
                except: f_idx = 0
                excl_field = st.selectbox("å­—æ®µå", current_cols, index=f_idx, key="ex_f")
            
            with ec2:
                if excl_field and excl_field in df_preview_bl.columns:
                    u_vals = df_preview_bl[excl_field].astype(str).unique().tolist()[:200]
                    excl_values = st.multiselect("å‰”é™¤å€¼ (Not In)", u_vals, default=def_vals, key="ex_v")
                else:
                    excl_values = []

            if excl_values:
                st.session_state["exclusions"] = [{"field": excl_field, "values": excl_values}]
            else:
                st.session_state["exclusions"] = []
                
        if st.session_state.get("exclusions"):
            r = st.session_state["exclusions"][0]
            st.info(f"å½“å‰å‰”é™¤: `{r['field']}` NOT IN {r['values']}")

        # ==========================================
        # [Step D] å¤‡æ³¨ & ä¿å­˜é…ç½®
        # ==========================================
        st.markdown("##### ğŸ“ å¤‡æ³¨")
        st.text_area("åˆ†æå¤‡æ³¨", key="calc_note", height=80)

        st.divider()
        if st.button("ğŸ’¾ ä¿å­˜æ‰€æœ‰é…ç½®"):
            payload = {
                "baseline": st.session_state.get("baseline_config", {}),
                "calc_rules": st.session_state.get("calc_rules", []),
                "note": st.session_state.get("calc_note", ""),
                "exclusions": st.session_state.get("exclusions", []),
                "pivot": {
                    "index": st.session_state.get("pivot_index", []),
                    "columns": st.session_state.get("pivot_columns", []),
                    "values": st.session_state.get("pivot_values", []),
                    "agg": st.session_state.get("pivot_aggs", ["Mean - å¹³å‡å€¼"]),
                    "view": st.session_state.get("pivot_view_mode", "classic"),
                    "row_order": {
                        "field": st.session_state.get("pivot_row_order_field"),
                        "values": st.session_state.get(
                            "pivot_row_order_values", []
                        ),
                    },
                },
            }
            save_calculation_config(selected_row["setup_name"], payload)
            st.success("é…ç½®å·²ä¿å­˜ï¼")

        # =======================================================
        # ã€æœ€ç»ˆæ‰§è¡Œæµæ°´çº¿ã€‘Pass 1 -> BDS -> Filter -> Pass 2
        # =======================================================
        final_df = raw_df.copy()
        # 1. Pass 1 è®¡ç®—
        final_df = apply_calculations(final_df, st.session_state["calc_rules"])
        # 2. åŸºçº¿æ˜ å°„
        final_df = apply_baseline_mapping(final_df, st.session_state.get("baseline_config", {}))
        # 3. å‰”é™¤
        if st.session_state.get("exclusions"):
            for rule in st.session_state["exclusions"]:
                f, vals = rule.get("field"), rule.get("values")
                if f and f in final_df.columns and vals:
                    final_df = final_df[~final_df[f].astype(str).isin([str(v) for v in vals])]
        # 4. Pass 2 è®¡ç®— (Change è§„åˆ™ç”Ÿæ•ˆ)
        final_df = apply_calculations(final_df, st.session_state["calc_rules"])

        # ==========================================
        # [Step E] é€è§†åˆ†æ & ç»Ÿè®¡æ£€éªŒ & ç»˜å›¾
        # ==========================================
        st.divider()
        st.subheader("ğŸ“Š é€è§†åˆ†æ & ç»Ÿè®¡æ£€éªŒ")

        # æ•°æ®é¢„è§ˆ
        with st.expander("ğŸ“„ æœ€ç»ˆæ•°æ®é¢„è§ˆ"):
            st.dataframe(final_df.head(100), width="stretch")
            st.download_button(
                "ğŸ“¥ ä¸‹è½½æœ€ç»ˆæ•°æ®",
                df_to_csv_bytes(final_df, index=False),
                "final_data.csv",
            )

        all_final_cols = list(final_df.columns)

        def normalize_pivot_selection(key: str) -> None:
            cur = st.session_state.get(key, [])
            if isinstance(cur, str):
                cur_list = [cur]
            elif cur is None:
                cur_list = []
            elif isinstance(cur, (list, tuple, set)):
                cur_list = list(cur)
            else:
                cur_list = [cur]
            st.session_state[key] = [c for c in cur_list if c in all_final_cols]

        normalize_pivot_selection("pivot_index")
        normalize_pivot_selection("pivot_columns")
        normalize_pivot_selection("pivot_values")

        def sync_pivot_row_order(
            field: str, available_values: list[str]
        ) -> list[str]:
            stored_field = st.session_state.get("pivot_row_order_field")
            stored_values = st.session_state.get("pivot_row_order_values", [])
            if not isinstance(stored_values, list):
                stored_values = list(stored_values)

            if stored_field != field:
                st.session_state["pivot_row_order_field"] = field
                st.session_state["pivot_row_order_values"] = list(available_values)
                return st.session_state["pivot_row_order_values"]

            new_order = [v for v in stored_values if v in available_values]
            new_order.extend([v for v in available_values if v not in new_order])
            st.session_state["pivot_row_order_values"] = new_order
            return new_order
        
        c1, c2, c3, c4 = st.columns(4)
        with c1:
            idx = st.multiselect("è¡Œç»´åº¦ (å¦‚ Visit)", all_final_cols, key="pivot_index")
        with c2:
            col = st.multiselect("åˆ—ç»´åº¦ (å¦‚ Group)", all_final_cols, key="pivot_columns")
        with c3:
            val = st.multiselect("å€¼å­—æ®µ (å¦‚ Score)", all_final_cols, key="pivot_values")
        with c4:
            agg_options = list(AGG_METHODS.keys())
            default_aggs = [
                a for a in st.session_state.get("pivot_aggs", ["Mean - å¹³å‡å€¼"])
                if a in agg_options
            ]
            if not default_aggs:
                default_aggs = ["Mean - å¹³å‡å€¼"]
            aggs = st.multiselect(
                "èšåˆå‡½æ•°ï¼ˆå¯å¤šé€‰ï¼‰",
                agg_options,
                default=default_aggs,
                key="pivot_aggs",
            )

        view_labels = {"classic": "ç»å…¸é€è§†è¡¨", "nested": "åµŒå¥—é€è§†è¡¨"}
        view_options = list(view_labels.values())
        current_view = st.session_state.get("pivot_view_mode", "classic")
        current_label = view_labels.get(current_view, view_options[0])
        try:
            view_index = view_options.index(current_label)
        except ValueError:
            view_index = 0
        view_choice = st.radio(
            "é€è§†è¡¨è§†å›¾",
            view_options,
            index=view_index,
            horizontal=True,
        )
        selected_view = next(
            key for key, label in view_labels.items() if label == view_choice
        )
        st.session_state["pivot_view_mode"] = selected_view

        row_order_values = None
        if idx:
            first_field = idx[0]
            if first_field in final_df.columns:
                available_values = (
                    final_df[first_field]
                    .dropna()
                    .astype(str)
                    .drop_duplicates()
                    .tolist()
                )
            else:
                available_values = []
            row_order_values = sync_pivot_row_order(
                first_field, available_values
            )

            with st.expander(f"è¡Œç»´åº¦é¡ºåºï¼ˆ{first_field}ï¼‰", expanded=False):
                if not row_order_values:
                    st.caption("æš‚æ— å¯æ’åºçš„å€¼ã€‚")
                else:
                    selected_value = st.selectbox(
                        "é€‰æ‹©è¦ç§»åŠ¨çš„å€¼",
                        row_order_values,
                        key="pivot_row_order_selected",
                    )
                    move_up, move_down = st.columns(2)
                    if move_up.button("ä¸Šç§»", key="pivot_row_order_up"):
                        new_order = list(row_order_values)
                        idx_pos = new_order.index(selected_value)
                        if idx_pos > 0:
                            new_order[idx_pos - 1], new_order[idx_pos] = (
                                new_order[idx_pos],
                                new_order[idx_pos - 1],
                            )
                            st.session_state["pivot_row_order_values"] = new_order
                            row_order_values = new_order
                    if move_down.button("ä¸‹ç§»", key="pivot_row_order_down"):
                        new_order = list(row_order_values)
                        idx_pos = new_order.index(selected_value)
                        if idx_pos < len(new_order) - 1:
                            new_order[idx_pos + 1], new_order[idx_pos] = (
                                new_order[idx_pos],
                                new_order[idx_pos + 1],
                            )
                            st.session_state["pivot_row_order_values"] = new_order
                            row_order_values = new_order
                    st.caption("å½“å‰é¡ºåºï¼š" + " â†’ ".join(row_order_values))

        if idx and col and val and aggs:
            # 1. é€è§†è¡¨
            try:
                view_mode = st.session_state.get("pivot_view_mode", "classic")
                if view_mode == "nested":
                    nested_data = render_pivot_nested(
                        final_df,
                        index_cols=idx,
                        column_cols=col,
                        value_cols=val,
                        agg_names=aggs,
                        row_order=row_order_values,
                    )
                    st.download_button(
                        "ğŸ“¥ ä¸‹è½½åµŒå¥—é€è§†è¡¨ï¼ˆExcelï¼‰",
                        nested_pivot_to_excel_bytes(nested_data),
                        "pivot_table_nested.xlsx",
                    )
                else:
                    pivot = render_pivot_classic(
                        final_df,
                        index_cols=idx,
                        column_cols=col,
                        value_cols=val,
                        agg_names=aggs,
                        row_order=row_order_values,
                    )
                    st.download_button(
                        "ğŸ“¥ ä¸‹è½½é€è§†è¡¨",
                        df_to_csv_bytes(pivot, index=True),
                        "pivot_table_multi_agg.csv",
                    )
            except Exception as e:
                st.error(f"é€è§†å¤±è´¥: {e}")

            # 2. [è‡ªåŠ¨åŒ–] ç»„é—´å·®å¼‚æ£€éªŒ (ANOVA)
            # è‡ªåŠ¨ä½¿ç”¨é€è§†è¡¨çš„é…ç½®ï¼šIndex=åˆ†å±‚, Col=åˆ†ç»„, Val=æ•°å€¼
            if len(idx) == 1 and len(col) == 1 and len(val) == 1:
                st.markdown("#### ğŸ“‰ ç»„é—´å·®å¼‚æ£€éªŒ (One-Way ANOVA)")
                st.caption(f"è‡ªåŠ¨è®¡ç®—ï¼šæŒ‰ **{idx[0]}** åˆ†å±‚ï¼Œæ¯”è¾ƒä¸åŒ **{col[0]}** ç»„åˆ«ä¹‹é—´çš„ **{val[0]}** å·®å¼‚ã€‚")
                
                anova_df = calculate_anova_table(
                    final_df, 
                    index_col=idx[0], 
                    group_col=col[0], 
                    value_col=val[0]
                )
                st.dataframe(anova_df, width="stretch")

            # 3. ç»˜å›¾ï¼ˆæ”¯æŒå¤šè¡Œç»´åº¦ / å¤šåˆ—ç»´åº¦ï¼ŒæŒ‰è¿ªå¡å°”ç§¯ç”Ÿæˆå•å…ƒæ ¼ï¼‰
            if val:
                if len(val) > 1:
                    st.info("å½“å‰å›¾è¡¨ä»…æ”¯æŒå•ä¸€å€¼å­—æ®µç»˜å›¾ï¼Œè¯·åœ¨â€œå€¼å­—æ®µâ€ä¸­åªé€‰æ‹©ä¸€ä¸ªã€‚")
                else:
                    st.markdown("---")
                    st.subheader("ğŸ“ˆ å•å…ƒæ ¼åˆ†å¸ƒå›¾")

                    # é¢„ç•™ä¸€ä¸ªä½ç½®ç”¨äºæ˜¾ç¤ºâ€œå·²ç”Ÿæˆ X ä¸ªå›¾è¡¨ï¼ˆæ—¶é—´ï¼‰â€çš„æç¤º
                    charts_info_placeholder = st.empty()

                    # æ”¶é›†å½“å‰é¡µé¢å®é™…ç»˜åˆ¶çš„æ‰€æœ‰å›¾è¡¨ï¼Œç”¨äº HTML å¯¼å‡º
                    all_figs: list[dict[str, Any]] = []

                    # è®¡ç®—è¡Œç»´åº¦å’Œåˆ—ç»´åº¦çš„æ‰€æœ‰ç»„åˆé”®ï¼ˆå¤šç»´ï¼‰
                    row_key_cols = idx
                    col_key_cols = col

                    if row_key_cols:
                        row_keys_df = (
                            final_df[row_key_cols]
                            .dropna()
                            .astype(str)
                            .drop_duplicates()
                        )
                        row_keys = row_keys_df.to_dict(orient="records")
                    else:
                        row_keys = [{}]

                    if col_key_cols:
                        col_keys_df = (
                            final_df[col_key_cols]
                            .dropna()
                            .astype(str)
                            .drop_duplicates()
                        )
                        col_keys = col_keys_df.to_dict(orient="records")
                    else:
                        col_keys = [{}]

                    total_charts = len(row_keys) * len(col_keys)
                    if total_charts == 0:
                        st.info("å½“å‰é€è§†é…ç½®ä¸‹æ²¡æœ‰å¯ç”¨äºç»˜å›¾çš„å•å…ƒæ ¼ã€‚")
                    else:
                        max_charts = 120
                        if total_charts > max_charts:
                            st.warning(
                                f"âš ï¸ å›¾è¡¨æ•°é‡è¾ƒå¤šï¼ˆ{total_charts} ä¸ªï¼‰ã€‚"
                                f" é»˜è®¤ä»…å±•ç¤ºå‰ {max_charts} ä¸ªï¼Œå¯å‹¾é€‰ä¸‹æ–¹é€‰é¡¹åŠ è½½å…¨éƒ¨ã€‚"
                            )
                            render_all = st.checkbox(
                                f"åŠ è½½å…¨éƒ¨ {total_charts} ä¸ªå›¾è¡¨ï¼ˆå¯èƒ½è¾ƒæ…¢ï¼‰",
                                key="charts_render_all",
                            )
                            limit = total_charts if render_all else max_charts
                        else:
                            limit = total_charts

                        count = 0
                        def_id_idx = next(
                            (i for i, c in enumerate(all_final_cols) if "SUBJ" in c.upper()),
                            0,
                        )
                        subj_col = st.selectbox(
                            "ID åˆ— (ç”¨äºç»˜å›¾)", all_final_cols, index=def_id_idx
                        )
                        value_col = val[0]
                        chart_type = st.radio(
                            "å›¾è¡¨ç±»å‹",
                            ["ç»å…¸", "ç»Ÿä¸€åæ ‡"],
                            horizontal=True,
                            key="chart_type_mode",
                        )

                        use_uniform_chart = chart_type == "ç»Ÿä¸€åæ ‡"
                        uniform_x_range = None
                        uniform_y_max = None
                        if use_uniform_chart:
                            st.markdown(
                                """
                                <style>
                                div[data-testid="stPlotlyChart"] > div {
                                    width: 100% !important;
                                    aspect-ratio: 1 / 1;
                                }
                                div[data-testid="stPlotlyChart"] .js-plotly-plot,
                                div[data-testid="stPlotlyChart"] .plot-container,
                                div[data-testid="stPlotlyChart"] .svg-container {
                                    width: 100% !important;
                                    height: 100% !important;
                                }
                                </style>
                                """,
                                unsafe_allow_html=True,
                            )
                            uniform_x_range, uniform_y_max = compute_uniform_axes(
                                final_df, row_key_cols, col_key_cols, value_col
                            )
                            if uniform_y_max <= 0:
                                uniform_x_range = None
                                uniform_y_max = None

                        agg_names_for_plot = aggs[:2]
                        agg_funcs_for_plot = [
                            AGG_METHODS.get(name) for name in agg_names_for_plot
                        ]
                        # ç»˜å›¾ä½¿ç”¨çš„èšåˆå‡½æ•°ï¼šå–å¤šé€‰èšåˆå‡½æ•°ä¸­çš„ç¬¬ä¸€ä¸ªä½œä¸ºå‚è€ƒçº¿
                        primary_agg_name = aggs[0] if aggs else "Mean - å¹³å‡å€¼"
                        actual_func_for_plot = AGG_METHODS.get(primary_agg_name, "mean")

                    # ä¸ºæ¯ä¸ªè¡Œç»„åˆåˆ†é…ä¸€ä¸ªå›ºå®šé¢œè‰²ï¼Œä½¿åŒä¸€è¡Œç»„åˆä¸‹ä¸åŒåˆ—ç»´åº¦çš„å›¾è¡¨é¢œè‰²ä¸€è‡´
                    color_palette = [
                        "#1f77b4",
                        "#ff7f0e",
                        "#2ca02c",
                        "#d62728",
                        "#9467bd",
                        "#8c564b",
                        "#e377c2",
                        "#7f7f7f",
                        "#bcbd22",
                        "#17becf",
                    ]

                    max_cols_per_row = 3

                    def render_cell_chart(
                        row_key: dict,
                        col_key: dict,
                        row_idx: int,
                        col_idx: int,
                        chart_color: str,
                    ) -> None:
                        nonlocal count

                        cell = final_df
                        for col_name, v in row_key.items():
                            cell = cell[cell[col_name].astype(str) == v]
                        for col_name, v in col_key.items():
                            cell = cell[cell[col_name].astype(str) == v]

                        if cell.empty:
                            return

                        title_parts = [
                            f"{k}={row_key[k]}" for k in row_key_cols if k in row_key
                        ] + [
                            f"{k}={col_key[k]}" for k in col_key_cols if k in col_key
                        ]
                        title = "<br>".join(title_parts) if title_parts else "(All)"
                        title_html = "<br>".join(
                            [html.escape(p) for p in title_parts]
                        ) if title_parts else "(All)"
                        internal_title = ""
                        key_suffix = f"r{row_idx}_c{col_idx}"

                        if use_uniform_chart:
                            fig = build_uniform_spaghetti_fig(
                                df=cell,
                                subj_col=subj_col,
                                value_col=value_col,
                                title=internal_title,
                                x_range=uniform_x_range,
                                y_max_count=uniform_y_max,
                                agg_funcs=agg_funcs_for_plot,
                                agg_names=agg_names_for_plot,
                                marker_color=chart_color,
                            )
                        else:
                            fig = build_spaghetti_fig(
                                df=cell,
                                subj_col=subj_col,
                                value_col=value_col,
                                title=internal_title,
                                agg_func=actual_func_for_plot,
                                agg_name=primary_agg_name,
                                marker_color=chart_color,
                            )
                        if fig is None:
                            return

                        st.markdown(
                            (
                                "<div style='text-align:center;"
                                "font-weight:600;font-size:16px;"
                                "line-height:1.2;margin-bottom:8px;'>"
                                f"{title_html}</div>"
                            ),
                            unsafe_allow_html=True,
                        )

                        # -------------------------------------------------------
                        # ğŸš€ å…³é”®ç‚¹ 2: æ·±æ‹·è´éš”ç¦» (Deep Copy Isolation)
                        # -------------------------------------------------------
                        # åœ¨ render ä¹‹å‰ï¼Œå…ˆå…‹éš†ä¸€ä»½â€œå¹²å‡€â€çš„ Figure ç”¨äºå¯¼å‡ºã€‚
                        # è¿™æ ·æ— è®º st.plotly_chart å¯¹ fig åšäº†ä»€ä¹ˆ(å¦‚æ³¨å…¥JSå›è°ƒ)ï¼Œ
                        # å¯¼å‡ºç”¨çš„ fig_for_export æ°¸è¿œæ˜¯çº¯å‡€çš„ã€‚
                        fig_for_export = copy.deepcopy(fig)

                        legend_items = []
                        meta = getattr(fig.layout, "meta", None)
                        if isinstance(meta, dict):
                            legend_items = meta.get("legend_items", [])

                        if use_uniform_chart:
                            render_uniform_spaghetti_fig(
                                fig, key=f"c_{key_suffix}"
                            )
                            if legend_items:
                                legend_lines = []
                                for item in legend_items:
                                    dash_style = (
                                        "dashed"
                                        if item.get("dash") == "dash"
                                        else "solid"
                                    )
                                    label_text = html.escape(
                                        str(item.get("label", "Agg"))
                                    )
                                    value_text = item.get("value")
                                    try:
                                        value_fmt = f"{float(value_text):.2f}"
                                    except Exception:
                                        value_fmt = "-"
                                    legend_lines.append(
                                        "<div style='display:flex;"
                                        "justify-content:center;align-items:center;"
                                        "gap:8px;font-size:12px;color:#c00;"
                                        "line-height:1.2;margin-top:2px;'>"
                                        f"<span style='display:inline-block;"
                                        f"width:32px;border-top:3px {dash_style} #c00;'></span>"
                                        f"<span>{label_text}: {value_fmt}</span>"
                                        "</div>"
                                    )
                                st.markdown(
                                    (
                                        "<div style='margin-top:4px;'>"
                                        + "".join(legend_lines)
                                        + "</div>"
                                    ),
                                    unsafe_allow_html=True,
                                )
                        else:
                            render_spaghetti_fig(fig, key=f"c_{key_suffix}")

                        all_figs.append(
                            {
                                "title": title,
                                "title_html": title_html,
                                "fig": fig_for_export,
                                "legend_items": legend_items,
                                "chart_type": (
                                    "uniform" if use_uniform_chart else "classic"
                                ),
                            }
                        )
                        count += 1

                    stop_render = False
                    for i, rk in enumerate(row_keys):
                        if stop_render:
                            break
                        group_color = color_palette[i % len(color_palette)]

                        if use_uniform_chart:
                            for chunk_start in range(0, len(col_keys), max_cols_per_row):
                                if stop_render:
                                    break
                                chunk = col_keys[
                                    chunk_start : chunk_start + max_cols_per_row
                                ]
                                cols = st.columns(max_cols_per_row)
                                for col_pos, ck in enumerate(chunk):
                                    if count >= limit:
                                        stop_render = True
                                        break
                                    j = chunk_start + col_pos
                                    with cols[col_pos]:
                                        render_cell_chart(
                                            rk, ck, i, j, group_color
                                        )
                        else:
                            for j, ck in enumerate(col_keys):
                                if count >= limit:
                                    stop_render = True
                                    break
                                render_cell_chart(rk, ck, i, j, group_color)

                    # åœ¨å›¾è¡¨åŒºåŸŸé¡¶éƒ¨ç»™å‡ºç”Ÿæˆæ•°é‡å’Œæ—¶é—´æç¤º
                    from datetime import datetime

                    ts = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                    charts_info_placeholder.caption(
                        f"å·²ä¸ºæ‚¨ç”Ÿæˆ {count} ä¸ªå›¾è¡¨ï¼ˆ{ts})"
                    )

                    # 4. ä¸€é”®å¯¼å‡ºå½“å‰æ‰€æœ‰å›¾è¡¨ä¸º HTML
                    if count > 0 and all_figs:
                        if st.button("ğŸ“¥ ä¸‹è½½æ‰€æœ‰å›¾è¡¨ (HTML)", key="btn_export_charts"):
                            html_blocks: list[str] = []

                            # ã€DEBUG STARTã€‘ æ‰“å°ç¬¬ä¸€å¼ å›¾çš„ X è½´æ•°æ®ï¼Œçœ‹çœ‹æ˜¯æ•°å€¼è¿˜æ˜¯ä¸‹æ ‡
                            if all_figs:
                                first_fig = all_figs[0]["fig"]
                                # å°è¯•è·å– X è½´æ•°æ®ï¼ˆé€šå¸¸åœ¨ data[0].xï¼‰
                                try:
                                    x_sample = first_fig.data[0].x
                                    print(f"--- [DEBUG] Export Check ---")
                                    print(f"First Chart Title: {all_figs[0]['title']}")
                                    print(f"X Data Type: {type(x_sample)}")
                                    # æ‰“å°å‰ 10 ä¸ªå€¼
                                    print(f"X Data Sample: {list(x_sample)[:10] if hasattr(x_sample, '__iter__') else x_sample}")
                                    print(f"----------------------------")
                                except Exception as e:
                                    print(f"--- [DEBUG] Error reading x data: {e} ---")
                            # ã€DEBUG ENDã€‘

                            full_html = build_charts_export_html(all_figs)

                            st.download_button(
                                "â¬‡ï¸ ä¿å­˜ä¸º HTML æ–‡ä»¶",
                                data=full_html.encode("utf-8"),
                                file_name="all_charts.html",
                                mime="text/html",
                                key="btn_export_charts_download",
                            )

                    # 5. ç‚¹å‡»æ•£ç‚¹åå±•ç¤ºé€‰ä¸­å—è¯•è€…çš„å®Œæ•´æ˜ç»†
                    selected_id = st.session_state.get("selected_subject_id")
                    if selected_id is not None:
                        st.markdown("---")
                        st.subheader(f"ğŸ“„ å—è¯•è€…æ˜ç»†ï¼š{selected_id}")

                        if subj_col in final_df.columns:
                            subj_df = final_df[
                                final_df[subj_col].astype(str) == str(selected_id)
                            ]
                            if subj_df.empty:
                                st.info("å½“å‰æ•°æ®é›†ä¸­æœªæ‰¾åˆ°è¯¥å—è¯•è€…çš„è®°å½•ã€‚")
                            else:
                                st.dataframe(subj_df, width="stretch")
                        else:
                            st.info(
                                f"å½“å‰æ•°æ®ä¸­ä¸å­˜åœ¨å—è¯•è€…åˆ— `{subj_col}`ï¼Œæ— æ³•å±•ç¤ºæ˜ç»†ã€‚"
                            )

                        # æä¾›è·³è½¬åˆ°å—è¯•è€…æ¡£æ¡ˆé¡µé¢çš„å…¥å£
                        def build_subject_profile_url(subject_id: Any) -> str:
                            base_path = st_config.get_option("server.baseUrlPath") or ""
                            base_prefix = f"/{base_path.strip('/')}" if base_path else ""
                            query = urlencode({"subject_id": str(subject_id)})
                            return f"{base_prefix}/subject_profile?{query}"
                        
                        st.link_button(
                            "ğŸ” åœ¨æ–°æ ‡ç­¾é¡µæ‰“å¼€å—è¯•è€…æ¡£æ¡ˆ",
                            build_subject_profile_url(selected_id),
                        )

if __name__ == "__main__":
    main()
