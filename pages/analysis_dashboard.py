import json
from typing import Any, Dict, List

import pandas as pd
import streamlit as st
from scipy import stats  # ç”¨äºè®¡ç®— ANOVA

from settings import get_engine
from utils import (
    fetch_all_setups,
    fetch_setup_config,
    load_table_metadata,
    build_sql,
    save_calculation_config
)

# å¼•å…¥æ’ä»¶ç³»ç»Ÿ
from analysis_methods import CALC_METHODS, AGG_METHODS
# å¼•å…¥ç‹¬ç«‹çš„å›¾è¡¨ç»„ä»¶
from charts import draw_spaghetti_chart

st.set_page_config(page_title="åˆ†æä»ªè¡¨ç›˜", layout="wide")
st.title("ğŸ“Š åˆ†æä»ªè¡¨ç›˜")


# ==========================================
# æ ¸å¿ƒé€»è¾‘å±‚ (Core Logic)
# ==========================================

def run_analysis(config: Dict[str, Any]) -> tuple[str, pd.DataFrame]:
    """ETLå±‚ï¼šç”ŸæˆSQLå¹¶è·å–åŸå§‹æ•°æ®"""
    meta_data = load_table_metadata()
    
    selected_tables = config.get("selected_tables", [])
    table_columns_map = config.get("table_columns_map", {})
    filters = config.get("filters", {})
    subject_blocklist = config.get("subject_blocklist", "")

    sql = build_sql(
        selected_tables=selected_tables,
        table_columns_map=table_columns_map,
        filters=filters,
        subject_blocklist=subject_blocklist,
        meta_data=meta_data,
    )

    if not sql:
        st.error("é…ç½®é”™è¯¯ï¼šæ— æ³•ç”Ÿæˆæœ‰æ•ˆ SQLã€‚è¯·æ£€æŸ¥é€‰è¡¨æˆ–ç­›é€‰æ¡ä»¶ã€‚")
        return "", pd.DataFrame()

    engine = get_engine()
    with st.spinner("æ­£åœ¨æŸ¥è¯¢æ•°æ®åº“..."):
        # è®¾ç½®è¶…æ—¶é˜²æ­¢å¡æ­»
        with engine.connect().execution_options(timeout=60) as conn:
            df = pd.read_sql(sql, conn)
            
    return sql, df


def apply_baseline_mapping(df: pd.DataFrame, config: Dict) -> pd.DataFrame:
    """
    [BDS å¼•æ“] åŸºçº¿å˜é‡æ˜ å°„
    å°†çºµå‘æ•°æ® (Long Format) ä¸­çš„åŸºçº¿è¡Œæ•°å€¼ï¼Œæ¨ªå‘å¹¿æ’­åˆ°è¯¥å—è¯•è€…çš„æ¯ä¸€è¡Œã€‚
    """
    if not config or not isinstance(config, dict):
        return df
    
    subj_col = config.get("subj_col")
    visit_col = config.get("visit_col")
    baseline_val = config.get("baseline_val")
    target_cols = config.get("target_cols", [])

    if not (subj_col and visit_col and baseline_val and target_cols):
        return df
    
    # å®¹é”™ï¼šç¡®ä¿æ‰€éœ€åˆ—å­˜åœ¨
    available_targets = [c for c in target_cols if c in df.columns]
    if not available_targets:
        return df
    if subj_col not in df.columns or visit_col not in df.columns:
        return df

    # 1. æå–åŸºçº¿å­é›†
    # ç­›é€‰å‡º Visit == Baseline çš„è¡Œ
    bl_mask = df[visit_col].astype(str) == str(baseline_val)
    bl_df = df.loc[bl_mask, [subj_col] + available_targets].copy()
    
    # 2. é‡å‘½åç”Ÿæˆ _BL åç¼€
    rename_map = {col: f"{col}_BL" for col in available_targets}
    bl_df = bl_df.rename(columns=rename_map)
    
    # 3. å»é‡ (ç¡®ä¿æ¯ä¸ªå—è¯•è€…åªæœ‰ä¸€è¡ŒåŸºçº¿)
    bl_df = bl_df.drop_duplicates(subset=[subj_col])

    # 4. åˆå¹¶å›ä¸»è¡¨ (Left Join)
    merged_df = pd.merge(df, bl_df, on=subj_col, how="left")
    
    return merged_df


def apply_calculations(df: pd.DataFrame, rules: List[Dict]) -> pd.DataFrame:
    """
    [è®¡ç®—å¼•æ“] æ‰§è¡Œè®¡ç®—è§„åˆ™
    æ”¯æŒé™é»˜å¤±è´¥ï¼Œä»¥ä¾¿æ”¯æŒä¸¤æ®µå¼è®¡ç®— (Two-Pass Calculation)ã€‚
    """
    df_calc = df.copy()
    
    for rule in rules:
        try:
            name = rule['name']
            cols = rule['cols']
            method_name = rule['method']
            
            # éªŒè¯åˆ—æ˜¯å¦å­˜åœ¨
            valid_cols = [c for c in cols if c in df_calc.columns]
            
            # å¦‚æœæ‰€éœ€åˆ—ä¸å…¨ï¼ˆæ¯”å¦‚ç¼ºäº†åŸºçº¿åˆ—ï¼‰ï¼Œåœ¨ Pass 1 é˜¶æ®µè·³è¿‡
            if len(valid_cols) < len(cols):
                continue

            # å¼ºåˆ¶è½¬æ•°å€¼
            subset = df_calc[valid_cols].apply(pd.to_numeric, errors='coerce')

            # è°ƒç”¨æ’ä»¶
            if method_name in CALC_METHODS:
                calc_func = CALC_METHODS[method_name]
                df_calc[name] = calc_func(subset)
                
        except Exception:
            # é™é»˜å¤±è´¥ï¼Œå…è®¸ Pass 2 é‡è¯•
            pass
            
    return df_calc


def calculate_anova_table(df: pd.DataFrame, index_col: str, group_col: str, value_col: str) -> pd.DataFrame:
    """
    [ç»Ÿè®¡å¼•æ“] è®¡ç®—ç»„é—´å·®å¼‚ (One-Way ANOVA)
    è‡ªåŠ¨åŸºäºé€è§†è¡¨çš„ç»´åº¦è¿›è¡Œè®¡ç®—ã€‚
    """
    results = []
    
    # ç¡®ä¿æ•°å€¼æœ‰æ•ˆ
    clean_df = df.dropna(subset=[value_col, group_col])
    clean_df[value_col] = pd.to_numeric(clean_df[value_col], errors='coerce')
    
    # 1. éå†è¡Œç»´åº¦ (å¦‚: Day 14, Day 28)
    row_levels = clean_df[index_col].unique()
    
    for level in row_levels:
        # å–å‡ºè¿™ä¸€å±‚çš„æ•°æ®
        sub_df = clean_df[clean_df[index_col] == level]
        
        # 2. æŒ‰ç»„æå–æ•°æ®
        groups_data = []
        groups = sub_df[group_col].unique()
        
        if len(groups) < 2:
            results.append({
                "Layer": level, "F-value": None, "P-value": None, "Note": "ç»„æ•°ä¸è¶³(<2)"
            })
            continue
            
        # æå–æ¯ä¸€ç»„çš„æ•°å€¼åˆ—è¡¨
        for g in groups:
            vals = sub_df[sub_df[group_col] == g][value_col].dropna().values
            if len(vals) > 1: 
                groups_data.append(vals)
        
        # 3. è®¡ç®— F/P
        if len(groups_data) >= 2:
            try:
                f_stat, p_val = stats.f_oneway(*groups_data)
                results.append({
                    "Layer": level,
                    "F-value": f_stat,
                    "P-value": p_val,
                    "Note": "Significant" if p_val < 0.05 else ""
                })
            except Exception:
                results.append({"Layer": level, "F-value": None, "P-value": None, "Note": "Calc Error"})
        else:
            results.append({"Layer": level, "F-value": None, "P-value": None, "Note": "æ•°æ®ä¸è¶³"})
            
    res_df = pd.DataFrame(results)
    if not res_df.empty:
        # æ ¼å¼åŒ–æ˜¾ç¤º
        res_df["F-value"] = res_df["F-value"].apply(lambda x: f"{x:.3f}" if pd.notnull(x) else "-")
        res_df["P-value"] = res_df["P-value"].apply(lambda x: f"{x:.4f}" if pd.notnull(x) else "-")
        # æ’åº
        try:
            res_df = res_df.sort_values("Layer")
        except:
            pass
        
    return res_df


# ==========================================
# UI è¡¨ç°å±‚ (Main)
# ==========================================

def main() -> None:
    # --- 1. ä¾§è¾¹æ  ---
    with st.sidebar:
        st.header("ğŸ§© åˆ†æé›†é…ç½®")
        setups = fetch_all_setups()

        if not setups:
            st.info("æš‚æ— é…ç½®ã€‚è¯·å…ˆå»ä¸»é¡µåˆ›å»ºã€‚")
            return

        option_labels = [f"{row['setup_name']}" for row in setups]
        selected_label = st.selectbox("é€‰æ‹©é…ç½®", options=option_labels)
        selected_row = next(r for r in setups if f"{r['setup_name']}" == selected_label)
        
        if selected_row.get("description"):
            st.info(f"ğŸ“ **å¤‡æ³¨**: {selected_row['description']}")

    # --- 1.1 çŠ¶æ€ç®¡ç†ä¸åˆå§‹åŒ– ---
    if "current_setup_name" not in st.session_state:
        st.session_state["current_setup_name"] = selected_row["setup_name"]
        need_reload = True
    else:
        need_reload = st.session_state["current_setup_name"] != selected_row["setup_name"]

    if need_reload:
        st.session_state["current_setup_name"] = selected_row["setup_name"]
        
        cfg_pack = fetch_setup_config(selected_row["setup_name"]) or {}
        calc_cfg = cfg_pack.get("calculation") or {}
        if isinstance(calc_cfg, list): calc_cfg = {"calc_rules": calc_cfg}
        
        st.session_state["calc_rules"] = calc_cfg.get("calc_rules", [])
        st.session_state["calc_note"] = calc_cfg.get("note", "")
        st.session_state["exclusions"] = calc_cfg.get("exclusions", [])
        st.session_state["pivot_config"] = calc_cfg.get("pivot", {})
        st.session_state["baseline_config"] = calc_cfg.get("baseline", {}) 

        p_cfg = st.session_state["pivot_config"]
        st.session_state["pivot_index"] = p_cfg.get("index", [])
        st.session_state["pivot_columns"] = p_cfg.get("columns", [])
        st.session_state["pivot_values"] = p_cfg.get("values", [])
        st.session_state["pivot_agg"] = p_cfg.get("agg", "Mean - å¹³å‡å€¼")

        st.session_state.pop("raw_df", None)
        st.session_state.pop("current_sql", None)
        st.session_state.pop("selected_subject_id", None)

    # --- 2. åŠ è½½æºæ•°æ® ---
    if st.button("ğŸš€ åŠ è½½æºæ•°æ®", type="primary"):
        full_cfg = fetch_setup_config(selected_row["setup_name"])
        if full_cfg and full_cfg.get("extraction"):
            sql, df_res = run_analysis(full_cfg["extraction"])
            if not df_res.empty:
                st.session_state["raw_df"] = df_res
                st.session_state["current_sql"] = sql
                st.success(f"åŠ è½½æˆåŠŸï¼å…± {len(df_res)} è¡Œã€‚")
            else:
                st.warning("æŸ¥è¯¢ç»“æœä¸ºç©ºã€‚")

    # --- 3. æ•°æ®å¤„ç†æµæ°´çº¿ ---
    if "raw_df" in st.session_state:
        raw_df = st.session_state["raw_df"]
        
        # -------------------------------------------------------
        # ã€Pass 1: é¢„è®¡ç®—ã€‘
        # å…ˆç®—ä¸€éè¡ç”Ÿå˜é‡ (å¦‚ Total)ï¼Œä¸ºäº†è®©åŸºçº¿é…ç½®èƒ½é€‰åˆ°å®ƒä»¬
        # -------------------------------------------------------
        df_pass1 = apply_calculations(raw_df, st.session_state["calc_rules"])
        all_cols_pass1 = list(df_pass1.columns)

        with st.expander("æŸ¥çœ‹åŸå§‹ SQL"):
            st.code(st.session_state.get("current_sql", ""), language="sql")
        
        st.divider()

        # ==========================================
        # [Step A] åŸºçº¿å˜é‡æ˜ å°„ (BDS Engine)
        # ==========================================
        st.subheader("ğŸ§¬ åŸºçº¿å˜é‡æ˜ å°„ (BDS)")
        st.caption("åœ¨æ­¤å®šä¹‰åŸºçº¿ï¼Œç³»ç»Ÿä¼šè‡ªåŠ¨ç”Ÿæˆ `_BL` åç¼€å˜é‡ã€‚")
        
        bl_cfg = st.session_state.get("baseline_config", {})
        
        with st.expander("âš™ï¸ é…ç½®åŸºçº¿é€»è¾‘", expanded=not bool(bl_cfg)):
            c1, c2, c3 = st.columns(3)
            # æ™ºèƒ½çŒœæµ‹
            def_subj_idx = next((i for i, c in enumerate(all_cols_pass1) if "SUBJ" in c.upper()), 0)
            def_visit_idx = next((i for i, c in enumerate(all_cols_pass1) if "VISIT" in c.upper() or "AVISIT" in c.upper()), 0)

            with c1:
                subj_col = st.selectbox("å—è¯•è€… ID åˆ—", all_cols_pass1, index=def_subj_idx, key="bl_subj_ui")
            with c2:
                visit_col = st.selectbox("è®¿è§†/æ—¶é—´ç‚¹åˆ—", all_cols_pass1, index=def_visit_idx, key="bl_visit_ui")
            
            # åŠ¨æ€è·å–è®¿è§†åˆ—è¡¨
            if visit_col and visit_col in df_pass1.columns:
                unique_visits = sorted(df_pass1[visit_col].dropna().astype(str).unique().tolist())
            else:
                unique_visits = []
                
            with c3:
                try:
                    saved_bl_val = bl_cfg.get("baseline_val")
                    bl_idx = unique_visits.index(saved_bl_val) if saved_bl_val in unique_visits else 0
                except:
                    bl_idx = 0
                baseline_val = st.selectbox("å“ªä¸€ä¸ªè®¿è§†æ˜¯åŸºçº¿?", unique_visits, index=bl_idx, key="bl_val_ui")
            
            target_cols = st.multiselect(
                "é€‰æ‹©æ•°å€¼å˜é‡ (ç”Ÿæˆ _BL åˆ—)", 
                options=all_cols_pass1,
                default=[c for c in bl_cfg.get("target_cols", []) if c in all_cols_pass1],
                key="bl_targets_ui"
            )
            
            if st.button("âœ… åº”ç”¨åŸºçº¿é…ç½®"):
                st.session_state["baseline_config"] = {
                    "subj_col": subj_col, "visit_col": visit_col,
                    "baseline_val": baseline_val, "target_cols": target_cols
                }
                st.rerun()

        if st.session_state.get("baseline_config"):
            targets = st.session_state["baseline_config"].get("target_cols", [])
            if targets:
                st.info(f"å·²ç”Ÿæˆå˜é‡: {', '.join([t+'_BL' for t in targets])}")

        st.divider()

        # ==========================================
        # [Step B] è¡ç”Ÿå˜é‡è®¡ç®—
        # ==========================================
        st.subheader("ğŸ§® è¡ç”Ÿå˜é‡è®¡ç®—")
        
        # æ¨¡æ‹ŸåŸºçº¿æ˜ å°„ä»¥è·å–åˆ—å
        df_preview_bl = apply_baseline_mapping(df_pass1, st.session_state.get("baseline_config", {}))
        current_cols = list(df_preview_bl.columns) + [r['name'] for r in st.session_state["calc_rules"]]
        
        with st.expander("â• æ·»åŠ æ–°è®¡ç®—è§„åˆ™", expanded=True):
            c1, c2, c3, c4 = st.columns([2, 3, 2, 1])
            with c1: 
                new_name = st.text_input("æ–°å˜é‡å", placeholder="ä¾‹: Change_Score")
            with c2: 
                targets_sel = st.multiselect("å‚ä¸è®¡ç®—çš„åˆ—", options=current_cols)
            with c3: 
                method = st.selectbox("è®¡ç®—æ–¹å¼", options=list(CALC_METHODS.keys()))
            with c4:
                st.write(""); st.write("")
                if st.button("æ·»åŠ "):
                    if new_name and targets_sel:
                        st.session_state["calc_rules"].append({
                            "name": new_name, "cols": targets_sel, "method": method
                        })
                        st.rerun()

        if st.session_state["calc_rules"]:
            for i, rule in enumerate(st.session_state["calc_rules"]):
                c1, c2 = st.columns([8, 1])
                c1.markdown(f"**Step {i+1}:** `{rule['name']}` = **{rule['method']}** ({', '.join(rule['cols'])})")
                if c2.button("ğŸ—‘ï¸", key=f"del_rule_{i}"):
                    st.session_state["calc_rules"].pop(i)
                    st.rerun()

        # ==========================================
        # [Step C] æ•°æ®å‰”é™¤
        # ==========================================
        st.divider()
        st.markdown("##### ğŸ—‘ï¸ æ•°æ®å‰”é™¤è§„åˆ™")
        
        with st.expander("é…ç½®å‰”é™¤æ¡ä»¶"):
            ec1, ec2 = st.columns([2, 3])
            cur_excl = st.session_state.get("exclusions", [])
            def_field = cur_excl[0]["field"] if cur_excl else (current_cols[0] if current_cols else None)
            def_vals = cur_excl[0]["values"] if cur_excl else []
            
            with ec1:
                try: f_idx = current_cols.index(def_field) if def_field in current_cols else 0
                except: f_idx = 0
                excl_field = st.selectbox("å­—æ®µå", current_cols, index=f_idx, key="ex_f")
            
            with ec2:
                if excl_field and excl_field in df_preview_bl.columns:
                    u_vals = df_preview_bl[excl_field].astype(str).unique().tolist()[:200]
                    excl_values = st.multiselect("å‰”é™¤å€¼ (Not In)", u_vals, default=def_vals, key="ex_v")
                else:
                    excl_values = []

            if excl_values:
                st.session_state["exclusions"] = [{"field": excl_field, "values": excl_values}]
            else:
                st.session_state["exclusions"] = []
                
        if st.session_state.get("exclusions"):
            r = st.session_state["exclusions"][0]
            st.info(f"å½“å‰å‰”é™¤: `{r['field']}` NOT IN {r['values']}")

        # ==========================================
        # [Step D] ä¿å­˜
        # ==========================================
        st.markdown("##### ğŸ“ å¤‡æ³¨")
        st.text_area("åˆ†æå¤‡æ³¨", key="calc_note", height=80)

        st.divider()
        if st.button("ğŸ’¾ ä¿å­˜æ‰€æœ‰é…ç½®"):
            payload = {
                "baseline": st.session_state.get("baseline_config", {}),
                "calc_rules": st.session_state["calc_rules"],
                "note": st.session_state.get("calc_note", ""),
                "exclusions": st.session_state.get("exclusions", []),
                "pivot": {
                    "index": st.session_state.get("pivot_index"),
                    "columns": st.session_state.get("pivot_columns"),
                    "values": st.session_state.get("pivot_values"),
                    "agg": st.session_state.get("pivot_agg")
                }
            }
            save_calculation_config(selected_row["setup_name"], payload)
            st.success("é…ç½®å·²ä¿å­˜ï¼")

        # =======================================================
        # ã€æœ€ç»ˆæ‰§è¡Œæµæ°´çº¿ã€‘Pass 1 -> BDS -> Filter -> Pass 2
        # =======================================================
        final_df = raw_df.copy()
        # 1. Pass 1 è®¡ç®—
        final_df = apply_calculations(final_df, st.session_state["calc_rules"])
        # 2. åŸºçº¿æ˜ å°„
        final_df = apply_baseline_mapping(final_df, st.session_state.get("baseline_config", {}))
        # 3. å‰”é™¤
        if st.session_state.get("exclusions"):
            for rule in st.session_state["exclusions"]:
                f, vals = rule.get("field"), rule.get("values")
                if f and f in final_df.columns and vals:
                    final_df = final_df[~final_df[f].astype(str).isin([str(v) for v in vals])]
        # 4. Pass 2 è®¡ç®— (Change è§„åˆ™ç”Ÿæ•ˆ)
        final_df = apply_calculations(final_df, st.session_state["calc_rules"])

        # ==========================================
        # [Step E] é€è§†åˆ†æ & ç»Ÿè®¡æ£€éªŒ & ç»˜å›¾
        # ==========================================
        st.divider()
        st.subheader("ğŸ“Š é€è§†åˆ†æ & ç»Ÿè®¡æ£€éªŒ")

        # æ•°æ®é¢„è§ˆ
        with st.expander("ğŸ“„ æœ€ç»ˆæ•°æ®é¢„è§ˆ"):
            st.dataframe(final_df.head(100), use_container_width=True)
            st.download_button("ğŸ“¥ ä¸‹è½½æœ€ç»ˆæ•°æ®", final_df.to_csv(index=False).encode("utf-8-sig"), "final_data.csv")

        all_final_cols = list(final_df.columns)
        
        c1, c2, c3, c4 = st.columns(4)
        with c1: idx = st.multiselect("è¡Œç»´åº¦ (å¦‚ Visit)", all_final_cols, key="pivot_index")
        with c2: col = st.multiselect("åˆ—ç»´åº¦ (å¦‚ Group)", all_final_cols, key="pivot_columns")
        with c3: val = st.multiselect("å€¼å­—æ®µ (å¦‚ Score)", all_final_cols, key="pivot_values")
        with c4: agg = st.selectbox("èšåˆå‡½æ•°", list(AGG_METHODS.keys()), key="pivot_agg")

        if idx and col and val:
            # 1. é€è§†è¡¨
            try:
                p_src = final_df.copy()
                for v in val: p_src[v] = pd.to_numeric(p_src[v], errors='coerce')
                
                actual_func = AGG_METHODS.get(agg, "mean")
                pivot = pd.pivot_table(p_src, index=idx, columns=col, values=val, aggfunc=actual_func)
                st.dataframe(pivot, use_container_width=True)
                st.download_button("ğŸ“¥ ä¸‹è½½é€è§†è¡¨", pivot.to_csv().encode("utf-8-sig"), "pivot_table.csv")
            except Exception as e:
                st.error(f"é€è§†å¤±è´¥: {e}")

            # 2. [è‡ªåŠ¨åŒ–] ç»„é—´å·®å¼‚æ£€éªŒ (ANOVA)
            # è‡ªåŠ¨ä½¿ç”¨é€è§†è¡¨çš„é…ç½®ï¼šIndex=åˆ†å±‚, Col=åˆ†ç»„, Val=æ•°å€¼
            if len(idx) == 1 and len(col) == 1 and len(val) == 1:
                st.markdown("#### ğŸ“‰ ç»„é—´å·®å¼‚æ£€éªŒ (One-Way ANOVA)")
                st.caption(f"è‡ªåŠ¨è®¡ç®—ï¼šæŒ‰ **{idx[0]}** åˆ†å±‚ï¼Œæ¯”è¾ƒä¸åŒ **{col[0]}** ç»„åˆ«ä¹‹é—´çš„ **{val[0]}** å·®å¼‚ã€‚")
                
                anova_df = calculate_anova_table(
                    final_df, 
                    index_col=idx[0], 
                    group_col=col[0], 
                    value_col=val[0]
                )
                st.dataframe(anova_df, use_container_width=True)

            # 3. ç»˜å›¾
            if len(idx) == 1 and len(col) == 1 and len(val) == 1:
                st.markdown("---")
                st.subheader("ğŸ“ˆ å•å…ƒæ ¼åˆ†å¸ƒå›¾")
                row_vals = final_df[idx[0]].dropna().astype(str).drop_duplicates().tolist()
                col_vals = final_df[col[0]].dropna().astype(str).drop_duplicates().tolist()
                
                if len(row_vals) * len(col_vals) > 20:
                    st.warning("âš ï¸ å›¾è¡¨è¿‡å¤šï¼Œä»…å±•ç¤ºå‰ 20 ä¸ªã€‚")
                
                count = 0
                def_id_idx = next((i for i, c in enumerate(all_final_cols) if "SUBJ" in c.upper()), 0)
                subj_col = st.selectbox("ID åˆ— (ç”¨äºç»˜å›¾)", all_final_cols, index=def_id_idx)
                
                for rv in row_vals:
                    for cv in col_vals:
                        if count >= 20:
                            break
                        cell = final_df[
                            (final_df[idx[0]].astype(str) == rv)
                            & (final_df[col[0]].astype(str) == cv)
                        ]
                        draw_spaghetti_chart(
                            cell, subj_col, val[0], f"{rv} | {cv}", f"c_{rv}_{cv}", actual_func, agg
                        )
                        count += 1

                # 4. ç‚¹å‡»æ•£ç‚¹åå±•ç¤ºé€‰ä¸­å—è¯•è€…çš„å®Œæ•´æ˜ç»†
                selected_id = st.session_state.get("selected_subject_id")
                if selected_id is not None:
                    st.markdown("---")
                    st.subheader(f"ğŸ“„ å—è¯•è€…æ˜ç»†ï¼š{selected_id}")

                    if subj_col in final_df.columns:
                        subj_df = final_df[
                            final_df[subj_col].astype(str) == str(selected_id)
                        ]
                        if subj_df.empty:
                            st.info("å½“å‰æ•°æ®é›†ä¸­æœªæ‰¾åˆ°è¯¥å—è¯•è€…çš„è®°å½•ã€‚")
                        else:
                            st.dataframe(subj_df, use_container_width=True)
                    else:
                        st.info(f"å½“å‰æ•°æ®ä¸­ä¸å­˜åœ¨å—è¯•è€…åˆ— `{subj_col}`ï¼Œæ— æ³•å±•ç¤ºæ˜ç»†ã€‚")

                    # æä¾›è·³è½¬åˆ°å—è¯•è€…æ¡£æ¡ˆé¡µé¢çš„å…¥å£
                    if st.button("ğŸ” æŸ¥çœ‹è¯¥å—è¯•è€…çš„è·¨è¡¨æ¡£æ¡ˆ", key="btn_subject_profile"):
                        st.session_state["selected_subject_id"] = selected_id
                        try:
                            st.switch_page("pages/subject_profile.py")
                        except Exception:
                            st.info("è¯·åœ¨å·¦ä¾§é¡µé¢åˆ—è¡¨ä¸­æ‰“å¼€â€œå—è¯•è€…æ¡£æ¡ˆâ€é¡µé¢ã€‚")

if __name__ == "__main__":
    main()
