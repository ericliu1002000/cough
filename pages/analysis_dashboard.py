import json
from typing import Any, Dict, List

import pandas as pd
import copy
import streamlit as st
from scipy import stats  # ç”¨äºè®¡ç®— ANOVA

from settings import get_engine
from utils import (
    fetch_all_setups,
    fetch_setup_config,
    load_table_metadata,
    build_sql,
    save_calculation_config
)

# å¼•å…¥æ’ä»¶ç³»ç»Ÿ
from analysis_methods import CALC_METHODS, AGG_METHODS
# å¼•å…¥ç‹¬ç«‹çš„å›¾è¡¨ç»„ä»¶
from charts import draw_spaghetti_chart, build_spaghetti_fig, render_spaghetti_fig

st.set_page_config(page_title="åˆ†æä»ªè¡¨ç›˜", layout="wide")
st.title("ğŸ“Š åˆ†æä»ªè¡¨ç›˜")


# ==========================================
# æ ¸å¿ƒé€»è¾‘å±‚ (Core Logic)
# ==========================================

def run_analysis(config: Dict[str, Any]) -> tuple[str, pd.DataFrame]:
    """ETLå±‚ï¼šç”ŸæˆSQLå¹¶è·å–åŸå§‹æ•°æ®"""
    meta_data = load_table_metadata()
    
    selected_tables = config.get("selected_tables", [])
    table_columns_map = config.get("table_columns_map", {})
    filters = config.get("filters", {})
    subject_blocklist = config.get("subject_blocklist", "")

    sql = build_sql(
        selected_tables=selected_tables,
        table_columns_map=table_columns_map,
        filters=filters,
        subject_blocklist=subject_blocklist,
        meta_data=meta_data,
    )

    if not sql:
        st.error("é…ç½®é”™è¯¯ï¼šæ— æ³•ç”Ÿæˆæœ‰æ•ˆ SQLã€‚è¯·æ£€æŸ¥é€‰è¡¨æˆ–ç­›é€‰æ¡ä»¶ã€‚")
        return "", pd.DataFrame()

    engine = get_engine()
    with st.spinner("æ­£åœ¨æŸ¥è¯¢æ•°æ®åº“..."):
        # è®¾ç½®è¶…æ—¶é˜²æ­¢å¡æ­»
        with engine.connect().execution_options(timeout=60) as conn:
            df = pd.read_sql(sql, conn)
            
    return sql, df


def apply_baseline_mapping(df: pd.DataFrame, config: Dict) -> pd.DataFrame:
    """
    [BDS å¼•æ“] åŸºçº¿å˜é‡æ˜ å°„
    å°†çºµå‘æ•°æ® (Long Format) ä¸­çš„åŸºçº¿è¡Œæ•°å€¼ï¼Œæ¨ªå‘å¹¿æ’­åˆ°è¯¥å—è¯•è€…çš„æ¯ä¸€è¡Œã€‚
    """
    if not config or not isinstance(config, dict):
        return df
    
    subj_col = config.get("subj_col")
    visit_col = config.get("visit_col")
    baseline_val = config.get("baseline_val")
    target_cols = config.get("target_cols", [])

    if not (subj_col and visit_col and baseline_val and target_cols):
        return df
    
    # å®¹é”™ï¼šç¡®ä¿æ‰€éœ€åˆ—å­˜åœ¨
    available_targets = [c for c in target_cols if c in df.columns]
    if not available_targets:
        return df
    if subj_col not in df.columns or visit_col not in df.columns:
        return df

    # 1. æå–åŸºçº¿å­é›†
    # ç­›é€‰å‡º Visit == Baseline çš„è¡Œ
    bl_mask = df[visit_col].astype(str) == str(baseline_val)
    bl_df = df.loc[bl_mask, [subj_col] + available_targets].copy()
    
    # 2. é‡å‘½åç”Ÿæˆ _BL åç¼€
    rename_map = {col: f"{col}_BL" for col in available_targets}
    bl_df = bl_df.rename(columns=rename_map)
    
    # 3. å»é‡ (ç¡®ä¿æ¯ä¸ªå—è¯•è€…åªæœ‰ä¸€è¡ŒåŸºçº¿)
    bl_df = bl_df.drop_duplicates(subset=[subj_col])

    # 4. åˆå¹¶å›ä¸»è¡¨ (Left Join)
    merged_df = pd.merge(df, bl_df, on=subj_col, how="left")
    
    return merged_df


def apply_calculations(df: pd.DataFrame, rules: List[Dict]) -> pd.DataFrame:
    """
    [è®¡ç®—å¼•æ“] æ‰§è¡Œè®¡ç®—è§„åˆ™
    æ”¯æŒé™é»˜å¤±è´¥ï¼Œä»¥ä¾¿æ”¯æŒä¸¤æ®µå¼è®¡ç®— (Two-Pass Calculation)ã€‚
    """
    df_calc = df.copy()
    
    for rule in rules:
        try:
            name = rule['name']
            cols = rule['cols']
            method_name = rule['method']
            
            # éªŒè¯åˆ—æ˜¯å¦å­˜åœ¨
            valid_cols = [c for c in cols if c in df_calc.columns]
            
            # å¦‚æœæ‰€éœ€åˆ—ä¸å…¨ï¼ˆæ¯”å¦‚ç¼ºäº†åŸºçº¿åˆ—ï¼‰ï¼Œåœ¨ Pass 1 é˜¶æ®µè·³è¿‡
            if len(valid_cols) < len(cols):
                continue

            # å¼ºåˆ¶è½¬æ•°å€¼
            subset = df_calc[valid_cols].apply(pd.to_numeric, errors='coerce')

            # è°ƒç”¨æ’ä»¶
            if method_name in CALC_METHODS:
                calc_func = CALC_METHODS[method_name]
                df_calc[name] = calc_func(subset)
                
        except Exception:
            # é™é»˜å¤±è´¥ï¼Œå…è®¸ Pass 2 é‡è¯•
            pass
            
    return df_calc


def calculate_anova_table(df: pd.DataFrame, index_col: str, group_col: str, value_col: str) -> pd.DataFrame:
    """
    [ç»Ÿè®¡å¼•æ“] è®¡ç®—ç»„é—´å·®å¼‚ (One-Way ANOVA)
    è‡ªåŠ¨åŸºäºé€è§†è¡¨çš„ç»´åº¦è¿›è¡Œè®¡ç®—ã€‚
    """
    results = []
    
    # ç¡®ä¿æ•°å€¼æœ‰æ•ˆ
    clean_df = df.dropna(subset=[value_col, group_col])
    clean_df[value_col] = pd.to_numeric(clean_df[value_col], errors='coerce')
    
    # 1. éå†è¡Œç»´åº¦ (å¦‚: Day 14, Day 28)
    row_levels = clean_df[index_col].unique()
    
    for level in row_levels:
        # å–å‡ºè¿™ä¸€å±‚çš„æ•°æ®
        sub_df = clean_df[clean_df[index_col] == level]
        
        # 2. æŒ‰ç»„æå–æ•°æ®
        groups_data = []
        groups = sub_df[group_col].unique()
        
        if len(groups) < 2:
            results.append({
                "Layer": level, "F-value": None, "P-value": None, "Note": "ç»„æ•°ä¸è¶³(<2)"
            })
            continue
            
        # æå–æ¯ä¸€ç»„çš„æ•°å€¼åˆ—è¡¨
        for g in groups:
            vals = sub_df[sub_df[group_col] == g][value_col].dropna().values
            if len(vals) > 1: 
                groups_data.append(vals)
        
        # 3. è®¡ç®— F/P
        if len(groups_data) >= 2:
            try:
                f_stat, p_val = stats.f_oneway(*groups_data)
                results.append({
                    "Layer": level,
                    "F-value": f_stat,
                    "P-value": p_val,
                    "Note": "Significant" if p_val < 0.05 else ""
                })
            except Exception:
                results.append({"Layer": level, "F-value": None, "P-value": None, "Note": "Calc Error"})
        else:
            results.append({"Layer": level, "F-value": None, "P-value": None, "Note": "æ•°æ®ä¸è¶³"})
            
    res_df = pd.DataFrame(results)
    if not res_df.empty:
        # æ ¼å¼åŒ–æ˜¾ç¤º
        res_df["F-value"] = res_df["F-value"].apply(lambda x: f"{x:.3f}" if pd.notnull(x) else "-")
        res_df["P-value"] = res_df["P-value"].apply(lambda x: f"{x:.4f}" if pd.notnull(x) else "-")
        # æ’åº
        try:
            res_df = res_df.sort_values("Layer")
        except:
            pass
        
    return res_df


# ==========================================
# UI è¡¨ç°å±‚ (Main)
# ==========================================

def main() -> None:
    # --- 1. ä¾§è¾¹æ  ---
    with st.sidebar:
        st.header("ğŸ§© åˆ†æé›†é…ç½®")
        setups = fetch_all_setups()

        if not setups:
            st.info("æš‚æ— é…ç½®ã€‚è¯·å…ˆå»ä¸»é¡µåˆ›å»ºã€‚")
            return

        option_labels = [f"{row['setup_name']}" for row in setups]
        selected_label = st.selectbox("é€‰æ‹©é…ç½®", options=option_labels)
        selected_row = next(r for r in setups if f"{r['setup_name']}" == selected_label)
        
        if selected_row.get("description"):
            st.info(f"ğŸ“ **å¤‡æ³¨**: {selected_row['description']}")

    # --- 1.1 çŠ¶æ€ç®¡ç†ä¸åˆå§‹åŒ– ---
    if "current_setup_name" not in st.session_state:
        st.session_state["current_setup_name"] = selected_row["setup_name"]
        need_reload = True
    else:
        need_reload = st.session_state["current_setup_name"] != selected_row["setup_name"]

    if need_reload:
        st.session_state["current_setup_name"] = selected_row["setup_name"]
        
        cfg_pack = fetch_setup_config(selected_row["setup_name"]) or {}
        calc_cfg = cfg_pack.get("calculation") or {}
        if isinstance(calc_cfg, list): calc_cfg = {"calc_rules": calc_cfg}
        
        st.session_state["calc_rules"] = calc_cfg.get("calc_rules", [])
        st.session_state["calc_note"] = calc_cfg.get("note", "")
        st.session_state["exclusions"] = calc_cfg.get("exclusions", [])
        st.session_state["pivot_config"] = calc_cfg.get("pivot", {})
        st.session_state["baseline_config"] = calc_cfg.get("baseline", {}) 

        p_cfg = st.session_state["pivot_config"]
        # å…¼å®¹å†å²æ•°æ®ï¼šæ—©æœŸç‰ˆæœ¬å¯èƒ½ä½¿ç”¨ç®€å•å­—ç¬¦ä¸² 'mean' ä½œä¸ºèšåˆå‡½æ•°åï¼Œ
        # ç°åœ¨ç»Ÿä¸€ä¸ºèšåˆå‡½æ•°åç§°åˆ—è¡¨ã€‚
        raw_agg = p_cfg.get("agg", ["Mean - å¹³å‡å€¼"])
        if isinstance(raw_agg, str):
            if raw_agg == "mean":
                raw_agg = "Mean - å¹³å‡å€¼"
            raw_aggs = [raw_agg]
        else:
            raw_aggs = list(raw_agg)

        st.session_state["pivot_index"] = p_cfg.get("index", [])
        st.session_state["pivot_columns"] = p_cfg.get("columns", [])
        st.session_state["pivot_values"] = p_cfg.get("values", [])
        st.session_state["pivot_aggs"] = raw_aggs

        st.session_state.pop("raw_df", None)
        st.session_state.pop("current_sql", None)
        st.session_state.pop("selected_subject_id", None)

    # --- 2. åŠ è½½æºæ•°æ® ---
    if st.button("ğŸš€ åŠ è½½æºæ•°æ®", type="primary"):
        full_cfg = fetch_setup_config(selected_row["setup_name"])
        if full_cfg and full_cfg.get("extraction"):
            sql, df_res = run_analysis(full_cfg["extraction"])
            if not df_res.empty:
                st.session_state["raw_df"] = df_res
                st.session_state["current_sql"] = sql
                st.success(f"åŠ è½½æˆåŠŸï¼å…± {len(df_res)} è¡Œã€‚")
            else:
                st.warning("æŸ¥è¯¢ç»“æœä¸ºç©ºã€‚")

    # --- 3. æ•°æ®å¤„ç†æµæ°´çº¿ ---
    if "raw_df" in st.session_state:
        raw_df = st.session_state["raw_df"]
        
        # -------------------------------------------------------
        # ã€Step 2ã€‘åŸå§‹ SQL + åŸå§‹æ•°æ®æ¸…å•é¢„è§ˆ
        # -------------------------------------------------------
        with st.expander("æŸ¥çœ‹åŸå§‹ SQL"):
            st.code(st.session_state.get("current_sql", ""), language="sql")

        # åŸå§‹æ•°æ®é¢„è§ˆï¼šå±•ç¤ºå®Œæ•´æ•°æ®æ¸…å•ï¼ˆå‡ ç™¾è¡Œçº§åˆ«ï¼‰
        with st.expander("ğŸ“„ åŸå§‹æ•°æ®é¢„è§ˆï¼ˆæŸ¥è¯¢ç»“æœï¼‰", expanded=False):
            st.dataframe(raw_df, width="stretch")
            st.download_button(
                "ğŸ“¥ ä¸‹è½½åŸå§‹æ•°æ®",
                raw_df.to_csv(index=False).encode("utf-8-sig"),
                "raw_data.csv",
            )

        st.divider()

        # -------------------------------------------------------
        # ã€Pass 1: é¢„è®¡ç®—ã€‘
        # å…ˆç®—ä¸€éè¡ç”Ÿå˜é‡ (å¦‚ Total)ï¼Œä¸ºäº†è®©åŸºçº¿é…ç½®èƒ½é€‰åˆ°å®ƒä»¬
        # -------------------------------------------------------
        df_pass1 = apply_calculations(raw_df, st.session_state["calc_rules"])
        all_cols_pass1 = list(df_pass1.columns)

        # ==========================================
        # [Step A] åŸºçº¿å˜é‡æ˜ å°„ (BDS Engine)
        # ==========================================
        st.subheader("ğŸ§¬ åŸºçº¿å˜é‡æ˜ å°„ (BDS)")
        st.caption("åœ¨æ­¤å®šä¹‰åŸºçº¿ï¼Œç³»ç»Ÿä¼šè‡ªåŠ¨ç”Ÿæˆ `_BL` åç¼€å˜é‡ã€‚")
        
        bl_cfg = st.session_state.get("baseline_config", {})
        
        with st.expander("âš™ï¸ é…ç½®åŸºçº¿é€»è¾‘", expanded=not bool(bl_cfg)):
            c1, c2, c3 = st.columns(3)
            # æ™ºèƒ½çŒœæµ‹
            def_subj_idx = next((i for i, c in enumerate(all_cols_pass1) if "SUBJ" in c.upper()), 0)
            def_visit_idx = next((i for i, c in enumerate(all_cols_pass1) if "VISIT" in c.upper() or "AVISIT" in c.upper()), 0)

            with c1:
                subj_col = st.selectbox("å—è¯•è€… ID åˆ—", all_cols_pass1, index=def_subj_idx, key="bl_subj_ui")
            with c2:
                visit_col = st.selectbox("è®¿è§†/æ—¶é—´ç‚¹åˆ—", all_cols_pass1, index=def_visit_idx, key="bl_visit_ui")
            
            # åŠ¨æ€è·å–è®¿è§†åˆ—è¡¨
            if visit_col and visit_col in df_pass1.columns:
                unique_visits = sorted(df_pass1[visit_col].dropna().astype(str).unique().tolist())
            else:
                unique_visits = []
                
            with c3:
                try:
                    saved_bl_val = bl_cfg.get("baseline_val")
                    bl_idx = unique_visits.index(saved_bl_val) if saved_bl_val in unique_visits else 0
                except:
                    bl_idx = 0
                baseline_val = st.selectbox("å“ªä¸€ä¸ªè®¿è§†æ˜¯åŸºçº¿?", unique_visits, index=bl_idx, key="bl_val_ui")
            
            target_cols = st.multiselect(
                "é€‰æ‹©æ•°å€¼å˜é‡ (ç”Ÿæˆ _BL åˆ—)", 
                options=all_cols_pass1,
                default=[c for c in bl_cfg.get("target_cols", []) if c in all_cols_pass1],
                key="bl_targets_ui"
            )
            
            if st.button("âœ… åº”ç”¨åŸºçº¿é…ç½®"):
                st.session_state["baseline_config"] = {
                    "subj_col": subj_col, "visit_col": visit_col,
                    "baseline_val": baseline_val, "target_cols": target_cols
                }
                st.rerun()

        if st.session_state.get("baseline_config"):
            targets = st.session_state["baseline_config"].get("target_cols", [])
            if targets:
                st.info(f"å·²ç”Ÿæˆå˜é‡: {', '.join([t+'_BL' for t in targets])}")

        st.divider()

        # ==========================================
        # [Step B] è¡ç”Ÿå˜é‡è®¡ç®—
        # ==========================================
        st.subheader("ğŸ§® è¡ç”Ÿå˜é‡è®¡ç®—")
        
        # æ¨¡æ‹ŸåŸºçº¿æ˜ å°„ä»¥è·å–åˆ—å
        df_preview_bl = apply_baseline_mapping(df_pass1, st.session_state.get("baseline_config", {}))
        current_cols = list(df_preview_bl.columns) + [r['name'] for r in st.session_state["calc_rules"]]
        
        with st.expander("â• æ·»åŠ æ–°è®¡ç®—è§„åˆ™", expanded=True):
            c1, c2, c3, c4 = st.columns([2, 3, 2, 1])
            with c1: 
                new_name = st.text_input("æ–°å˜é‡å", placeholder="ä¾‹: Change_Score")
            with c2: 
                targets_sel = st.multiselect("å‚ä¸è®¡ç®—çš„åˆ—", options=current_cols)
            with c3: 
                method = st.selectbox("è®¡ç®—æ–¹å¼", options=list(CALC_METHODS.keys()))
            with c4:
                st.write(""); st.write("")
                if st.button("æ·»åŠ "):
                    if new_name and targets_sel:
                        st.session_state["calc_rules"].append({
                            "name": new_name, "cols": targets_sel, "method": method
                        })
                        st.rerun()

        if st.session_state["calc_rules"]:
            for i, rule in enumerate(st.session_state["calc_rules"]):
                c1, c2 = st.columns([8, 1])
                c1.markdown(f"**Step {i+1}:** `{rule['name']}` = **{rule['method']}** ({', '.join(rule['cols'])})")
                if c2.button("ğŸ—‘ï¸", key=f"del_rule_{i}"):
                    st.session_state["calc_rules"].pop(i)
                    st.rerun()

        # ==========================================
        # [Step C] æ•°æ®å‰”é™¤
        # ==========================================
        st.divider()
        st.markdown("##### ğŸ—‘ï¸ æ•°æ®å‰”é™¤è§„åˆ™")
        
        with st.expander("é…ç½®å‰”é™¤æ¡ä»¶"):
            ec1, ec2 = st.columns([2, 3])
            cur_excl = st.session_state.get("exclusions", [])
            def_field = cur_excl[0]["field"] if cur_excl else (current_cols[0] if current_cols else None)
            def_vals = cur_excl[0]["values"] if cur_excl else []
            
            with ec1:
                try: f_idx = current_cols.index(def_field) if def_field in current_cols else 0
                except: f_idx = 0
                excl_field = st.selectbox("å­—æ®µå", current_cols, index=f_idx, key="ex_f")
            
            with ec2:
                if excl_field and excl_field in df_preview_bl.columns:
                    u_vals = df_preview_bl[excl_field].astype(str).unique().tolist()[:200]
                    excl_values = st.multiselect("å‰”é™¤å€¼ (Not In)", u_vals, default=def_vals, key="ex_v")
                else:
                    excl_values = []

            if excl_values:
                st.session_state["exclusions"] = [{"field": excl_field, "values": excl_values}]
            else:
                st.session_state["exclusions"] = []
                
        if st.session_state.get("exclusions"):
            r = st.session_state["exclusions"][0]
            st.info(f"å½“å‰å‰”é™¤: `{r['field']}` NOT IN {r['values']}")

        # ==========================================
        # [Step D] å¤‡æ³¨ & ä¿å­˜é…ç½®
        # ==========================================
        st.markdown("##### ğŸ“ å¤‡æ³¨")
        st.text_area("åˆ†æå¤‡æ³¨", key="calc_note", height=80)

        st.divider()
        if st.button("ğŸ’¾ ä¿å­˜æ‰€æœ‰é…ç½®"):
            payload = {
                "baseline": st.session_state.get("baseline_config", {}),
                "calc_rules": st.session_state.get("calc_rules", []),
                "note": st.session_state.get("calc_note", ""),
                "exclusions": st.session_state.get("exclusions", []),
                "pivot": {
                    "index": st.session_state.get("pivot_index", []),
                    "columns": st.session_state.get("pivot_columns", []),
                    "values": st.session_state.get("pivot_values", []),
                    "agg": st.session_state.get("pivot_aggs", ["Mean - å¹³å‡å€¼"]),
                },
            }
            save_calculation_config(selected_row["setup_name"], payload)
            st.success("é…ç½®å·²ä¿å­˜ï¼")

        # =======================================================
        # ã€æœ€ç»ˆæ‰§è¡Œæµæ°´çº¿ã€‘Pass 1 -> BDS -> Filter -> Pass 2
        # =======================================================
        final_df = raw_df.copy()
        # 1. Pass 1 è®¡ç®—
        final_df = apply_calculations(final_df, st.session_state["calc_rules"])
        # 2. åŸºçº¿æ˜ å°„
        final_df = apply_baseline_mapping(final_df, st.session_state.get("baseline_config", {}))
        # 3. å‰”é™¤
        if st.session_state.get("exclusions"):
            for rule in st.session_state["exclusions"]:
                f, vals = rule.get("field"), rule.get("values")
                if f and f in final_df.columns and vals:
                    final_df = final_df[~final_df[f].astype(str).isin([str(v) for v in vals])]
        # 4. Pass 2 è®¡ç®— (Change è§„åˆ™ç”Ÿæ•ˆ)
        final_df = apply_calculations(final_df, st.session_state["calc_rules"])

        # ==========================================
        # [Step E] é€è§†åˆ†æ & ç»Ÿè®¡æ£€éªŒ & ç»˜å›¾
        # ==========================================
        st.divider()
        st.subheader("ğŸ“Š é€è§†åˆ†æ & ç»Ÿè®¡æ£€éªŒ")

        # æ•°æ®é¢„è§ˆ
        with st.expander("ğŸ“„ æœ€ç»ˆæ•°æ®é¢„è§ˆ"):
            st.dataframe(final_df.head(100), width="stretch")
            st.download_button("ğŸ“¥ ä¸‹è½½æœ€ç»ˆæ•°æ®", final_df.to_csv(index=False).encode("utf-8-sig"), "final_data.csv")

        all_final_cols = list(final_df.columns)
        
        c1, c2, c3, c4 = st.columns(4)
        with c1:
            idx = st.multiselect("è¡Œç»´åº¦ (å¦‚ Visit)", all_final_cols, key="pivot_index")
        with c2:
            col = st.multiselect("åˆ—ç»´åº¦ (å¦‚ Group)", all_final_cols, key="pivot_columns")
        with c3:
            val = st.multiselect("å€¼å­—æ®µ (å¦‚ Score)", all_final_cols, key="pivot_values")
        with c4:
            agg_options = list(AGG_METHODS.keys())
            default_aggs = [
                a for a in st.session_state.get("pivot_aggs", ["Mean - å¹³å‡å€¼"])
                if a in agg_options
            ]
            if not default_aggs:
                default_aggs = ["Mean - å¹³å‡å€¼"]
            aggs = st.multiselect(
                "èšåˆå‡½æ•°ï¼ˆå¯å¤šé€‰ï¼‰",
                agg_options,
                default=default_aggs,
                key="pivot_aggs",
            )

        if idx and col and val and aggs:
            # 1. é€è§†è¡¨
            try:
                p_src = final_df.copy()
                for v in val:
                    p_src[v] = pd.to_numeric(p_src[v], errors="coerce")

                # ä¸ºæ¯ä¸ªå€¼å­—æ®µæŒ‡å®šä¸€ç»„èšåˆå‡½æ•°ï¼Œæ”¯æŒå¤šèšåˆ
                aggfunc_map = {
                    v: [AGG_METHODS.get(a, "mean") for a in aggs] for v in val
                }
                pivot = pd.pivot_table(
                    p_src,
                    index=idx,
                    columns=col,
                    values=val,
                    aggfunc=aggfunc_map,
                )
                st.dataframe(pivot, width="stretch")
                st.download_button(
                    "ğŸ“¥ ä¸‹è½½é€è§†è¡¨",
                    pivot.to_csv().encode("utf-8-sig"),
                    "pivot_table_multi_agg.csv",
                )
            except Exception as e:
                st.error(f"é€è§†å¤±è´¥: {e}")

            # 2. [è‡ªåŠ¨åŒ–] ç»„é—´å·®å¼‚æ£€éªŒ (ANOVA)
            # è‡ªåŠ¨ä½¿ç”¨é€è§†è¡¨çš„é…ç½®ï¼šIndex=åˆ†å±‚, Col=åˆ†ç»„, Val=æ•°å€¼
            if len(idx) == 1 and len(col) == 1 and len(val) == 1:
                st.markdown("#### ğŸ“‰ ç»„é—´å·®å¼‚æ£€éªŒ (One-Way ANOVA)")
                st.caption(f"è‡ªåŠ¨è®¡ç®—ï¼šæŒ‰ **{idx[0]}** åˆ†å±‚ï¼Œæ¯”è¾ƒä¸åŒ **{col[0]}** ç»„åˆ«ä¹‹é—´çš„ **{val[0]}** å·®å¼‚ã€‚")
                
                anova_df = calculate_anova_table(
                    final_df, 
                    index_col=idx[0], 
                    group_col=col[0], 
                    value_col=val[0]
                )
                st.dataframe(anova_df, width="stretch")

            # 3. ç»˜å›¾ï¼ˆæ”¯æŒå¤šè¡Œç»´åº¦ / å¤šåˆ—ç»´åº¦ï¼ŒæŒ‰è¿ªå¡å°”ç§¯ç”Ÿæˆå•å…ƒæ ¼ï¼‰
            if val:
                if len(val) > 1:
                    st.info("å½“å‰å›¾è¡¨ä»…æ”¯æŒå•ä¸€å€¼å­—æ®µç»˜å›¾ï¼Œè¯·åœ¨â€œå€¼å­—æ®µâ€ä¸­åªé€‰æ‹©ä¸€ä¸ªã€‚")
                else:
                    st.markdown("---")
                    st.subheader("ğŸ“ˆ å•å…ƒæ ¼åˆ†å¸ƒå›¾")

                    # é¢„ç•™ä¸€ä¸ªä½ç½®ç”¨äºæ˜¾ç¤ºâ€œå·²ç”Ÿæˆ X ä¸ªå›¾è¡¨ï¼ˆæ—¶é—´ï¼‰â€çš„æç¤º
                    charts_info_placeholder = st.empty()

                    # æ”¶é›†å½“å‰é¡µé¢å®é™…ç»˜åˆ¶çš„æ‰€æœ‰å›¾è¡¨ï¼Œç”¨äº HTML å¯¼å‡º
                    all_figs: list[tuple[str, Any]] = []

                    # è®¡ç®—è¡Œç»´åº¦å’Œåˆ—ç»´åº¦çš„æ‰€æœ‰ç»„åˆé”®ï¼ˆå¤šç»´ï¼‰
                    row_key_cols = idx
                    col_key_cols = col

                    if row_key_cols:
                        row_keys_df = (
                            final_df[row_key_cols]
                            .dropna()
                            .astype(str)
                            .drop_duplicates()
                        )
                        row_keys = row_keys_df.to_dict(orient="records")
                    else:
                        row_keys = [{}]

                    if col_key_cols:
                        col_keys_df = (
                            final_df[col_key_cols]
                            .dropna()
                            .astype(str)
                            .drop_duplicates()
                        )
                        col_keys = col_keys_df.to_dict(orient="records")
                    else:
                        col_keys = [{}]

                    total_charts = len(row_keys) * len(col_keys)
                    if total_charts == 0:
                        st.info("å½“å‰é€è§†é…ç½®ä¸‹æ²¡æœ‰å¯ç”¨äºç»˜å›¾çš„å•å…ƒæ ¼ã€‚")
                    else:
                        max_charts = 120
                        if total_charts > max_charts:
                            st.warning(
                                f"âš ï¸ å›¾è¡¨æ•°é‡è¾ƒå¤šï¼ˆ{total_charts} ä¸ªï¼‰ã€‚"
                                f" é»˜è®¤ä»…å±•ç¤ºå‰ {max_charts} ä¸ªï¼Œå¯å‹¾é€‰ä¸‹æ–¹é€‰é¡¹åŠ è½½å…¨éƒ¨ã€‚"
                            )
                            render_all = st.checkbox(
                                f"åŠ è½½å…¨éƒ¨ {total_charts} ä¸ªå›¾è¡¨ï¼ˆå¯èƒ½è¾ƒæ…¢ï¼‰",
                                key="charts_render_all",
                            )
                            limit = total_charts if render_all else max_charts
                        else:
                            limit = total_charts

                        count = 0
                        def_id_idx = next(
                            (i for i, c in enumerate(all_final_cols) if "SUBJ" in c.upper()),
                            0,
                        )
                        subj_col = st.selectbox(
                            "ID åˆ— (ç”¨äºç»˜å›¾)", all_final_cols, index=def_id_idx
                        )
                        value_col = val[0]
                        # ç»˜å›¾ä½¿ç”¨çš„èšåˆå‡½æ•°ï¼šå–å¤šé€‰èšåˆå‡½æ•°ä¸­çš„ç¬¬ä¸€ä¸ªä½œä¸ºå‚è€ƒçº¿
                        primary_agg_name = aggs[0] if aggs else "Mean - å¹³å‡å€¼"
                        actual_func_for_plot = AGG_METHODS.get(primary_agg_name, "mean")

                    # ä¸ºæ¯ä¸ªè¡Œç»„åˆåˆ†é…ä¸€ä¸ªå›ºå®šé¢œè‰²ï¼Œä½¿åŒä¸€è¡Œç»„åˆä¸‹ä¸åŒåˆ—ç»´åº¦çš„å›¾è¡¨é¢œè‰²ä¸€è‡´
                    color_palette = [
                        "#1f77b4",
                        "#ff7f0e",
                        "#2ca02c",
                        "#d62728",
                        "#9467bd",
                        "#8c564b",
                        "#e377c2",
                        "#7f7f7f",
                        "#bcbd22",
                        "#17becf",
                    ]

                    for i, rk in enumerate(row_keys):
                        group_color = color_palette[i % len(color_palette)]
                        for j, ck in enumerate(col_keys):
                            if count >= limit:
                                break

                            cell = final_df
                            for col_name, v in rk.items():
                                cell = cell[cell[col_name].astype(str) == v]
                            for col_name, v in ck.items():
                                cell = cell[cell[col_name].astype(str) == v]

                            if cell.empty:
                                continue

                            row_title = ", ".join(
                                [f"{k}={rk[k]}" for k in row_key_cols]
                            ) or "(All)"
                            col_title = ", ".join(
                                [f"{k}={ck[k]}" for k in col_key_cols]
                            ) or "(All)"
                            title = f"{row_title} | {col_title}"
                            key_suffix = f"r{i}_c{j}"

                            fig = build_spaghetti_fig(
                                df=cell,
                                subj_col=subj_col,
                                value_col=value_col,
                                title=title,
                                agg_func=actual_func_for_plot,
                                agg_name=primary_agg_name,
                                marker_color=group_color,
                            )
                            if fig is None:
                                continue

                            # -------------------------------------------------------
                            # ğŸš€ å…³é”®ç‚¹ 2: æ·±æ‹·è´éš”ç¦» (Deep Copy Isolation)
                            # -------------------------------------------------------
                            # åœ¨ render ä¹‹å‰ï¼Œå…ˆå…‹éš†ä¸€ä»½â€œå¹²å‡€â€çš„ Figure ç”¨äºå¯¼å‡ºã€‚
                            # è¿™æ ·æ— è®º st.plotly_chart å¯¹ fig åšäº†ä»€ä¹ˆ(å¦‚æ³¨å…¥JSå›è°ƒ)ï¼Œ
                            # å¯¼å‡ºç”¨çš„ fig_for_export æ°¸è¿œæ˜¯çº¯å‡€çš„ã€‚
                            fig_for_export = copy.deepcopy(fig)

                            render_spaghetti_fig(fig, key=f"c_{key_suffix}")
                            all_figs.append((title, fig))
                            count += 1

                    # åœ¨å›¾è¡¨åŒºåŸŸé¡¶éƒ¨ç»™å‡ºç”Ÿæˆæ•°é‡å’Œæ—¶é—´æç¤º
                    from datetime import datetime

                    ts = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                    charts_info_placeholder.caption(
                        f"å·²ä¸ºæ‚¨ç”Ÿæˆ {count} ä¸ªå›¾è¡¨ï¼ˆ{ts})"
                    )

                    # 4. ä¸€é”®å¯¼å‡ºå½“å‰æ‰€æœ‰å›¾è¡¨ä¸º HTML
                    if count > 0 and all_figs:
                        if st.button("ğŸ“¥ ä¸‹è½½æ‰€æœ‰å›¾è¡¨ (HTML)", key="btn_export_charts"):
                            html_blocks: list[str] = []

                            # ã€DEBUG STARTã€‘ æ‰“å°ç¬¬ä¸€å¼ å›¾çš„ X è½´æ•°æ®ï¼Œçœ‹çœ‹æ˜¯æ•°å€¼è¿˜æ˜¯ä¸‹æ ‡
                            if all_figs:
                                first_fig = all_figs[0][1]
                                # å°è¯•è·å– X è½´æ•°æ®ï¼ˆé€šå¸¸åœ¨ data[0].xï¼‰
                                try:
                                    x_sample = first_fig.data[0].x
                                    print(f"--- [DEBUG] Export Check ---")
                                    print(f"First Chart Title: {all_figs[0][0]}")
                                    print(f"X Data Type: {type(x_sample)}")
                                    # æ‰“å°å‰ 10 ä¸ªå€¼
                                    print(f"X Data Sample: {list(x_sample)[:10] if hasattr(x_sample, '__iter__') else x_sample}")
                                    print(f"----------------------------")
                                except Exception as e:
                                    print(f"--- [DEBUG] Error reading x data: {e} ---")
                            # ã€DEBUG ENDã€‘

                            for title, fig in all_figs:
                                fig_html = fig.to_html(
                                    full_html=False, include_plotlyjs=False
                                )
                                html_blocks.append(f"<h3>{title}</h3>\n{fig_html}")

                            full_html = (
                                "<html><head>"
                                "<meta charset='utf-8' />"
                                "<script src='https://cdn.plot.ly/plotly-latest.min.js'></script>"
                                "</head><body>"
                                + "\n<hr/>\n".join(html_blocks)
                                + "</body></html>"
                            )

                            st.download_button(
                                "â¬‡ï¸ ä¿å­˜ä¸º HTML æ–‡ä»¶",
                                data=full_html.encode("utf-8"),
                                file_name="all_charts.html",
                                mime="text/html",
                                key="btn_export_charts_download",
                            )

                    # 5. ç‚¹å‡»æ•£ç‚¹åå±•ç¤ºé€‰ä¸­å—è¯•è€…çš„å®Œæ•´æ˜ç»†
                    selected_id = st.session_state.get("selected_subject_id")
                    if selected_id is not None:
                        st.markdown("---")
                        st.subheader(f"ğŸ“„ å—è¯•è€…æ˜ç»†ï¼š{selected_id}")

                        if subj_col in final_df.columns:
                            subj_df = final_df[
                                final_df[subj_col].astype(str) == str(selected_id)
                            ]
                            if subj_df.empty:
                                st.info("å½“å‰æ•°æ®é›†ä¸­æœªæ‰¾åˆ°è¯¥å—è¯•è€…çš„è®°å½•ã€‚")
                            else:
                                st.dataframe(subj_df, width="stretch")
                        else:
                            st.info(
                                f"å½“å‰æ•°æ®ä¸­ä¸å­˜åœ¨å—è¯•è€…åˆ— `{subj_col}`ï¼Œæ— æ³•å±•ç¤ºæ˜ç»†ã€‚"
                            )

                        # æä¾›è·³è½¬åˆ°å—è¯•è€…æ¡£æ¡ˆé¡µé¢çš„å…¥å£
                        if st.button(
                            "ğŸ” æŸ¥çœ‹è¯¥å—è¯•è€…çš„è·¨è¡¨æ¡£æ¡ˆ", key="btn_subject_profile"
                        ):
                            st.session_state["selected_subject_id"] = selected_id
                            try:
                                st.switch_page("pages/subject_profile.py")
                            except Exception:
                                st.info("è¯·åœ¨å·¦ä¾§é¡µé¢åˆ—è¡¨ä¸­æ‰“å¼€â€œå—è¯•è€…æ¡£æ¡ˆâ€é¡µé¢ã€‚")

if __name__ == "__main__":
    main()
